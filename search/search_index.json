{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PCOT - the PanCam Operations Toolkit PCOT is a Python program and library which allows users to manipulate multispectral images and other data from the ExoMars Rosalind Franklin rover. This is an early alpha version with serious limitations. There is no calibration code of any kind (although the preliminaries are in place) PDS4 import capabilities are poor - we only support spec-rad products from the ExoMars PANCAM instrument - but we also support ENVI provided the images are 32-bit float BSQ RGB PNGs multispectral images made of multiple monochrome PNGs and adding new PDS4 formats should be relatively straightforward Data quality and uncertainty data are not yet handled in any way There are probably a lot of useful operations missing There are certainly a lot of bugs. Getting Started User Guide Dev Roadmap Reporting bugs There are known issues which can stop PCOT running - see issues . If your problem isn't described there, you should have been given the address and a user ID to access our bug tracking system. If you haven't, please contact the Aberystwyth team. Release history Can be found here","title":"PCOT - the PanCam Operations Toolkit"},{"location":"#pcot-the-pancam-operations-toolkit","text":"PCOT is a Python program and library which allows users to manipulate multispectral images and other data from the ExoMars Rosalind Franklin rover. This is an early alpha version with serious limitations. There is no calibration code of any kind (although the preliminaries are in place) PDS4 import capabilities are poor - we only support spec-rad products from the ExoMars PANCAM instrument - but we also support ENVI provided the images are 32-bit float BSQ RGB PNGs multispectral images made of multiple monochrome PNGs and adding new PDS4 formats should be relatively straightforward Data quality and uncertainty data are not yet handled in any way There are probably a lot of useful operations missing There are certainly a lot of bugs. Getting Started User Guide Dev Roadmap","title":"PCOT - the PanCam Operations Toolkit"},{"location":"#reporting-bugs","text":"There are known issues which can stop PCOT running - see issues . If your problem isn't described there, you should have been given the address and a user ID to access our bug tracking system. If you haven't, please contact the Aberystwyth team.","title":"Reporting bugs"},{"location":"#release-history","text":"Can be found here","title":"Release history"},{"location":"github/","text":"This page contains the contents of the README.md file in our repository, and describes how to install PCOT if you have access to the source code. PCOT This is the prototype of the Pancam Operations Toolkit. This is primarily a Python application and library for processing data from the Pancam instrument on the Rosalind Franklin rover, although it lends itself to any task involving processing multispectral image data. For example, with PCOT you can: * load ENVI and PDS4 multispectral images * load multiple images in other formats (e.g. PNG) and combine them into multispectral images * define regions of interest in the data * perform mathematical operations * view spectra and histograms and many other things besides. PCOT is highly extensible and open-source, so any missing functionality is easily added. PCOT operates on a graph model - the data is processed through a set of nodes which manipulate it in various ways (e.g. add regions of interest, perform maths, splice images together, merge image channels, plot spectra). A PCOT document describes this graph, and we intend that documents are distributed along with the data they generate to help reproducibility. Installing with Anaconda PCOT is a Python program (and library) with a number of dependencies, including Python >3.8 PySide2 OpenCV numpy scikit-image pyperclip (may also require other packages in Linux e.g. xsel) matplotlib I find the best way to manage these is to use Anaconda. Installation has been tested on Windows 10 and Ubuntu 20.04. The first thing you'll need to do is install Anaconda, which can be done from here: Windows: https://docs.anaconda.com/anaconda/install/linux/ Linux: https://docs.anaconda.com/anaconda/install/linux/ MacOS: https://docs.anaconda.com/anaconda/install/mac-os/ (untested) Obtain the software For both Windows and Ubuntu this is the obvious first step. This can be done by either downloading the archive from Github and extracting it into a new directory, or cloning the repository. In both cases, the top level directory should be called PCOT (this isn't really mandatory but makes the instructions below simpler). The best way to download is this: Make sure you have a Github account and membership of the AU-ExoMars group. Open an Anaconda shell window (see below) If you have an SSH key set up for GitHub, type this command into the shell ( changing the repository address if it is different ): git clone git@github.com:AU-ExoMars/PCOT.git Otherwise type this: git clone https://github.com/AU-ExoMars/PCOT.git You should now have a PCOT directory which will contain this file (as README.md) and quite a few others. Opening Anaconda's shell on different OSs Windows: Open the Anaconda PowerShell Prompt application, which will have been installed when you installed Anaconda. Linux and MacOS : just open a Bash shell Installing on Ubuntu / MacOS Assuming you have successfully installed Anaconda and cloned or downloaded PCOT as above: Open a bash shell cd to the PCOT directory (which contains this file). Run the command conda create -n pcot python=3.8 poetry . This will create an environment called pcot which uses Python 3.8 and the Poetry dependency and packaging manager. It may take some time. Activate the environment with conda activate pcot . Now run poetry install . This will set up all the packages PCOT is dependent on and install PCOT. You should now be able to run pcot to start the application. Installing on Windows Assuming you have successfully installed Anaconda and cloned or downloaded PCOT as above: Open the Anaconda PowerShell Prompt application from the Start Menu. cd to the PCOT directory (which contains this file). Run the command conda create -n pcot python=3.8 poetry . This will create an environment called pcot which uses Python 3.8 and the Poetry dependency and packaging manager. It may take some time. Activate the environment with conda activate pcot . Now run poetry install . This will set up all the packages PCOT is dependent on and install PCOT. You should now be able to run pcot to start the application. Running PCOT Open an Anaconda shell and run the following commands (assuming you installed PCOT into your home directory): cd PCOT conda activate pcot pcot Running PCOT inside Pycharm These instructions apply to Anaconda installations. First set up the Conda environment and interpreter: Open PyCharm and open the PCOT directory as an existing project. Open File/Settings.. (Ctrl+Alt+S) Select Project:PCOT / Python Interpreter If the Python Interpreter is not already Python 3.8 with something like anaconda3/envs/pcot/bin/python Select the cogwheel to the right of the Python Interpreter dropdown and then select Add . Select Conda Environment . Select Existing Environment . Select the environment: it should be something like anaconda3/envs/pcot/bin/python . Select OK . Now set up the run configuration: Select Edit Configurations... (or it might be Add Configuration... ) from the configurations drop down in the menu bar Add a new configuration (the + symbol) and select Python Set Script Path to PCOT/src/pcot/__main__.py Make sure the interpreter is something like Project Default (Python 3.8 (pcot)) , i.e. the Python interpreter of the pcot environment. You should now be able to run and debug PCOT. Environment variables It's a good idea, but not mandatory, to set the environment variable PCOTUSER to a string of the form name <email> . For example, in Linux I have added the following to my .bashrc file: export PCOT_USER=\"Jim Finnis <jcf12@aber.ac.uk>\" This data is added to all saved PCOT graphs. If the environment variable is not set, the username returned by Python's getpass module is used (e.g. 'jcf12'). Common runtime issues Can't start Qt on Linux This sometimes happens: qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"\" even though it was found. This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem. Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, webgl, xcb. Try this: export QT_DEBUG_PLUGINS=1 pcot to run the program again, and look at the output. You might see errors like this (I've removed some stuff): QFactoryLoader::QFactoryLoader() checking directory path \"[...]envs/pcot/bin/platforms\" ... Cannot load library [...]/plugins/platforms/libqxcb.so: (libxcb-xinerama.so.0: cannot open shared object file: No such file or directory) QLibraryPrivate::loadPlugin failed on \"...[stuff removed].. (libxcb-xinerama.so.0: cannot open shared object file: No such file or directory)\" If that's the case, install the missing package: sudo apt install libxcb-xinerama0 That should help. Otherwise, send a message to us with the output from the QT_DEBUG_PLUGINS run and we will investigate.","title":"Github"},{"location":"github/#pcot","text":"This is the prototype of the Pancam Operations Toolkit. This is primarily a Python application and library for processing data from the Pancam instrument on the Rosalind Franklin rover, although it lends itself to any task involving processing multispectral image data. For example, with PCOT you can: * load ENVI and PDS4 multispectral images * load multiple images in other formats (e.g. PNG) and combine them into multispectral images * define regions of interest in the data * perform mathematical operations * view spectra and histograms and many other things besides. PCOT is highly extensible and open-source, so any missing functionality is easily added. PCOT operates on a graph model - the data is processed through a set of nodes which manipulate it in various ways (e.g. add regions of interest, perform maths, splice images together, merge image channels, plot spectra). A PCOT document describes this graph, and we intend that documents are distributed along with the data they generate to help reproducibility.","title":"PCOT"},{"location":"github/#installing-with-anaconda","text":"PCOT is a Python program (and library) with a number of dependencies, including Python >3.8 PySide2 OpenCV numpy scikit-image pyperclip (may also require other packages in Linux e.g. xsel) matplotlib I find the best way to manage these is to use Anaconda. Installation has been tested on Windows 10 and Ubuntu 20.04. The first thing you'll need to do is install Anaconda, which can be done from here: Windows: https://docs.anaconda.com/anaconda/install/linux/ Linux: https://docs.anaconda.com/anaconda/install/linux/ MacOS: https://docs.anaconda.com/anaconda/install/mac-os/ (untested)","title":"Installing with Anaconda"},{"location":"github/#obtain-the-software","text":"For both Windows and Ubuntu this is the obvious first step. This can be done by either downloading the archive from Github and extracting it into a new directory, or cloning the repository. In both cases, the top level directory should be called PCOT (this isn't really mandatory but makes the instructions below simpler). The best way to download is this: Make sure you have a Github account and membership of the AU-ExoMars group. Open an Anaconda shell window (see below) If you have an SSH key set up for GitHub, type this command into the shell ( changing the repository address if it is different ): git clone git@github.com:AU-ExoMars/PCOT.git Otherwise type this: git clone https://github.com/AU-ExoMars/PCOT.git You should now have a PCOT directory which will contain this file (as README.md) and quite a few others.","title":"Obtain the software"},{"location":"github/#opening-anacondas-shell-on-different-oss","text":"Windows: Open the Anaconda PowerShell Prompt application, which will have been installed when you installed Anaconda. Linux and MacOS : just open a Bash shell","title":"Opening Anaconda's shell on different OSs"},{"location":"github/#installing-on-ubuntu-macos","text":"Assuming you have successfully installed Anaconda and cloned or downloaded PCOT as above: Open a bash shell cd to the PCOT directory (which contains this file). Run the command conda create -n pcot python=3.8 poetry . This will create an environment called pcot which uses Python 3.8 and the Poetry dependency and packaging manager. It may take some time. Activate the environment with conda activate pcot . Now run poetry install . This will set up all the packages PCOT is dependent on and install PCOT. You should now be able to run pcot to start the application.","title":"Installing on Ubuntu / MacOS"},{"location":"github/#installing-on-windows","text":"Assuming you have successfully installed Anaconda and cloned or downloaded PCOT as above: Open the Anaconda PowerShell Prompt application from the Start Menu. cd to the PCOT directory (which contains this file). Run the command conda create -n pcot python=3.8 poetry . This will create an environment called pcot which uses Python 3.8 and the Poetry dependency and packaging manager. It may take some time. Activate the environment with conda activate pcot . Now run poetry install . This will set up all the packages PCOT is dependent on and install PCOT. You should now be able to run pcot to start the application.","title":"Installing on Windows"},{"location":"github/#running-pcot","text":"Open an Anaconda shell and run the following commands (assuming you installed PCOT into your home directory): cd PCOT conda activate pcot pcot","title":"Running PCOT"},{"location":"github/#running-pcot-inside-pycharm","text":"These instructions apply to Anaconda installations. First set up the Conda environment and interpreter: Open PyCharm and open the PCOT directory as an existing project. Open File/Settings.. (Ctrl+Alt+S) Select Project:PCOT / Python Interpreter If the Python Interpreter is not already Python 3.8 with something like anaconda3/envs/pcot/bin/python Select the cogwheel to the right of the Python Interpreter dropdown and then select Add . Select Conda Environment . Select Existing Environment . Select the environment: it should be something like anaconda3/envs/pcot/bin/python . Select OK . Now set up the run configuration: Select Edit Configurations... (or it might be Add Configuration... ) from the configurations drop down in the menu bar Add a new configuration (the + symbol) and select Python Set Script Path to PCOT/src/pcot/__main__.py Make sure the interpreter is something like Project Default (Python 3.8 (pcot)) , i.e. the Python interpreter of the pcot environment. You should now be able to run and debug PCOT.","title":"Running PCOT inside Pycharm"},{"location":"github/#environment-variables","text":"It's a good idea, but not mandatory, to set the environment variable PCOTUSER to a string of the form name <email> . For example, in Linux I have added the following to my .bashrc file: export PCOT_USER=\"Jim Finnis <jcf12@aber.ac.uk>\" This data is added to all saved PCOT graphs. If the environment variable is not set, the username returned by Python's getpass module is used (e.g. 'jcf12').","title":"Environment variables"},{"location":"github/#common-runtime-issues","text":"","title":"Common runtime issues"},{"location":"github/#cant-start-qt-on-linux","text":"This sometimes happens: qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"\" even though it was found. This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem. Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, webgl, xcb. Try this: export QT_DEBUG_PLUGINS=1 pcot to run the program again, and look at the output. You might see errors like this (I've removed some stuff): QFactoryLoader::QFactoryLoader() checking directory path \"[...]envs/pcot/bin/platforms\" ... Cannot load library [...]/plugins/platforms/libqxcb.so: (libxcb-xinerama.so.0: cannot open shared object file: No such file or directory) QLibraryPrivate::loadPlugin failed on \"...[stuff removed].. (libxcb-xinerama.so.0: cannot open shared object file: No such file or directory)\" If that's the case, install the missing package: sudo apt install libxcb-xinerama0 That should help. Otherwise, send a message to us with the output from the QT_DEBUG_PLUGINS run and we will investigate.","title":"Can't start Qt on Linux"},{"location":"releases/","text":"Releases Production releases None Beta releases None Alpha releases 0.2.0-alpha 2022-04-21 ANJARDEN SPRING \"pixel scanning\" on canvases, shows spectrum of pixel when active custom cursor, pixel under cursor highlighted at high zooms text toggle button (currently unused) fixes to example plugin added macos.spec for pyinstaller archive system shows progress when loading each archive element Issue 1 fix (multiple tab closes when main window reinitialised) dynamic type determination for expr output can connect incompatible node outputs to inputs; indicated as red arrows infinite recursion in ROI nodes fix splash screen for Windows/Linux pyinstaller startup (not yet supported on MacOS pyinstaller) custom Datum and connection brush types now easy expr resizing regression fix multiple input buttons after load/resize fix status bar repaints on ui.msg, so it's updated in load and perform context menu on editable text caused a crash (bug in Qt). Workaround. comment boxes 0.1.0-alpha 2022-03-02 ALSIA WELL Initial alpha release outside Aberystwyth","title":"Releases"},{"location":"releases/#releases","text":"","title":"Releases"},{"location":"releases/#production-releases","text":"None","title":"Production releases"},{"location":"releases/#beta-releases","text":"None","title":"Beta releases"},{"location":"releases/#alpha-releases","text":"","title":"Alpha releases"},{"location":"releases/#020-alpha-2022-04-21-anjarden-spring","text":"\"pixel scanning\" on canvases, shows spectrum of pixel when active custom cursor, pixel under cursor highlighted at high zooms text toggle button (currently unused) fixes to example plugin added macos.spec for pyinstaller archive system shows progress when loading each archive element Issue 1 fix (multiple tab closes when main window reinitialised) dynamic type determination for expr output can connect incompatible node outputs to inputs; indicated as red arrows infinite recursion in ROI nodes fix splash screen for Windows/Linux pyinstaller startup (not yet supported on MacOS pyinstaller) custom Datum and connection brush types now easy expr resizing regression fix multiple input buttons after load/resize fix status bar repaints on ui.msg, so it's updated in load and perform context menu on editable text caused a crash (bug in Qt). Workaround. comment boxes","title":"0.2.0-alpha 2022-04-21 ANJARDEN SPRING"},{"location":"releases/#010-alpha-2022-03-02-alsia-well","text":"Initial alpha release outside Aberystwyth","title":"0.1.0-alpha 2022-03-02 ALSIA WELL"},{"location":"roadmap/","text":"Development roadmap This is a rough guide, and things may change! Next release: BEACON HUT Open source! PDS4 importer with proctools Ad-hoc Spectrum viewer in canvas Significant rewrite of expression execution code, permitting custom types to have operations defined on them Direct input method for library use Improved default RGB mapping in canvas Testing Basics testing Testing of the operating principles (see Principles ) Source rules ROI rules rect node can now be edited numerically circle node can add circular ROIs, which can be edited numerically. Future releases Data quality uncertainty map pixel data bits canvas viewer for both the above error propagation in expr and all nodes (see Principles ) Testing quality rules Documentation User guide Page each on the main elements of the UI Page on expr nodes documentation for properties of nodes for library use (e.g. expr nodes have \".expr\") How-to for common tasks Obtain user stories for analysis of HK data (which could potentially get messy, as these are likely to be time series) Consider a vector type It might be useful if functions such as max(), sd() etc. produced a vector of a values rather than a single value in multiband image contexts. For example, a 4-band image with the first channel set to 1 while all others are zero could produce a mean vector of [1,0,0,0]. We would then perform a max() on this vector to get a single value. Preparing for filter aberration and de-hardwiring cameras: Actual values removed from filters.py and put into a config file PANCAM/AUPE camera types no longer hardwired but got from that config Filter aberration parameters added to this config Filter aberration Node (or func??) to convert aberration to image Calculate and process in canvas spectrum Calculate and process in spectrum node","title":"Roadmap"},{"location":"roadmap/#development-roadmap","text":"This is a rough guide, and things may change!","title":"Development roadmap"},{"location":"roadmap/#next-release-beacon-hut","text":"Open source! PDS4 importer with proctools Ad-hoc Spectrum viewer in canvas Significant rewrite of expression execution code, permitting custom types to have operations defined on them Direct input method for library use Improved default RGB mapping in canvas Testing Basics testing Testing of the operating principles (see Principles ) Source rules ROI rules rect node can now be edited numerically circle node can add circular ROIs, which can be edited numerically.","title":"Next release: BEACON HUT"},{"location":"roadmap/#future-releases","text":"Data quality uncertainty map pixel data bits canvas viewer for both the above error propagation in expr and all nodes (see Principles ) Testing quality rules Documentation User guide Page each on the main elements of the UI Page on expr nodes documentation for properties of nodes for library use (e.g. expr nodes have \".expr\") How-to for common tasks Obtain user stories for analysis of HK data (which could potentially get messy, as these are likely to be time series) Consider a vector type It might be useful if functions such as max(), sd() etc. produced a vector of a values rather than a single value in multiband image contexts. For example, a 4-band image with the first channel set to 1 while all others are zero could produce a mean vector of [1,0,0,0]. We would then perform a max() on this vector to get a single value. Preparing for filter aberration and de-hardwiring cameras: Actual values removed from filters.py and put into a config file PANCAM/AUPE camera types no longer hardwired but got from that config Filter aberration parameters added to this config Filter aberration Node (or func??) to convert aberration to image Calculate and process in canvas spectrum Calculate and process in spectrum node","title":"Future releases"},{"location":"autodocs/","text":"Autodocs Below are automatically generated documents for certain entities in PCOT. These are generated by running the generate_autodocs.py script in the mkdocs directory. Nodes Nodes are the entities which make up a PCOT document's graph, taking inputs from various sources and manipulating them in various ways. comment constant contrast stretch croproi crosscalib curve decorr stretch dummy dump expr gradient histequal histogram importroi in input 0 input 1 input 2 input 3 inset manual register multidot normimage offset out painted pct poly rect show number sink spectrum stitch striproi tvl1 autoreg Expr functions Below are functions which can be used in the expression evaluation node, expr . name params opt. params description addroi image,roi add ROI to image clip image clip all channels of an image to 0-1 cos angle calculate cosine of angle in radians crop image,x,y,w,h crop an image to a rectangle curve image,mul,add impose a sigmoid curve on an image, y=1/(1+e^-(mx+a))) where m and a are parameters grey image useCV convert an image to greyscale max val... find the maximum value of pixels in a list of ROIs, images or values mean val... find the mean of pixels in a list of ROIs, images or values merge image... merge a number of images into a single image - if the image has multiple channels they will all be merged in. min val... find the minimum value of pixels in a list of ROIs, images or values norm image splitchans normalize all channels of an image to 0-1, operating on all channels combined (the default) or separately roi image extract ROI from image (returns rect ROI on entire image if none is present sd val... find the standard deviation of pixels in a list of ROIs, images or values sin angle calculate sine of angle in radians sqrt angle calculate the square root sum val... find the sum of pixels in a list of ROIs, images or values tan angle calculate tangent of angle in radians Expr properties Below are properties which can be used in the expression evaluation node, expr . Properties are names which can be used as identifiers on the right hand side of a \".\" operator, such as a.w to get the width of an image a . name type of x desc x.w img give the width of an image in pixels (if there are ROIs, give the width of the BB of the ROI union) x.w roi give the width of an ROI in pixels x.h img give the height of an image in pixels (if there are ROIs, give the width of the BB of the ROI union) x.h roi give the width of an ROI in pixels x.n img give the area of an image in pixels (if there are ROIs, give the number of pixels in the ROI union) x.n roi give the number of pixels in an ROI","title":"Autodocs"},{"location":"autodocs/#autodocs","text":"Below are automatically generated documents for certain entities in PCOT. These are generated by running the generate_autodocs.py script in the mkdocs directory.","title":"Autodocs"},{"location":"autodocs/#nodes","text":"Nodes are the entities which make up a PCOT document's graph, taking inputs from various sources and manipulating them in various ways. comment constant contrast stretch croproi crosscalib curve decorr stretch dummy dump expr gradient histequal histogram importroi in input 0 input 1 input 2 input 3 inset manual register multidot normimage offset out painted pct poly rect show number sink spectrum stitch striproi tvl1 autoreg","title":"Nodes"},{"location":"autodocs/#expr-functions","text":"Below are functions which can be used in the expression evaluation node, expr . name params opt. params description addroi image,roi add ROI to image clip image clip all channels of an image to 0-1 cos angle calculate cosine of angle in radians crop image,x,y,w,h crop an image to a rectangle curve image,mul,add impose a sigmoid curve on an image, y=1/(1+e^-(mx+a))) where m and a are parameters grey image useCV convert an image to greyscale max val... find the maximum value of pixels in a list of ROIs, images or values mean val... find the mean of pixels in a list of ROIs, images or values merge image... merge a number of images into a single image - if the image has multiple channels they will all be merged in. min val... find the minimum value of pixels in a list of ROIs, images or values norm image splitchans normalize all channels of an image to 0-1, operating on all channels combined (the default) or separately roi image extract ROI from image (returns rect ROI on entire image if none is present sd val... find the standard deviation of pixels in a list of ROIs, images or values sin angle calculate sine of angle in radians sqrt angle calculate the square root sum val... find the sum of pixels in a list of ROIs, images or values tan angle calculate tangent of angle in radians","title":"Expr functions"},{"location":"autodocs/#expr-properties","text":"Below are properties which can be used in the expression evaluation node, expr . Properties are names which can be used as identifiers on the right hand side of a \".\" operator, such as a.w to get the width of an image a . name type of x desc x.w img give the width of an image in pixels (if there are ROIs, give the width of the BB of the ROI union) x.w roi give the width of an ROI in pixels x.h img give the height of an image in pixels (if there are ROIs, give the width of the BB of the ROI union) x.h roi give the width of an ROI in pixels x.n img give the area of an image in pixels (if there are ROIs, give the number of pixels in the ROI union) x.n roi give the number of pixels in an ROI","title":"Expr properties"},{"location":"autodocs/comment/","text":"comment Description Comment box Connections","title":"comment"},{"location":"autodocs/comment/#comment","text":"","title":"comment"},{"location":"autodocs/comment/#description","text":"Comment box","title":"Description"},{"location":"autodocs/comment/#connections","text":"","title":"Connections"},{"location":"autodocs/constant/","text":"constant Description Generates a numeric value which can be typed directly into the node's box in the graph Connections Outputs Index Name Type Desc 0 (none) number (none)","title":"constant"},{"location":"autodocs/constant/#constant","text":"","title":"constant"},{"location":"autodocs/constant/#description","text":"Generates a numeric value which can be typed directly into the node's box in the graph","title":"Description"},{"location":"autodocs/constant/#connections","text":"","title":"Connections"},{"location":"autodocs/constant/#outputs","text":"Index Name Type Desc 0 (none) number (none)","title":"Outputs"},{"location":"autodocs/contrast_stretch/","text":"contrast stretch Description Perform a simple contrast stretch separately on each channel. The stretch is linear around the midpoint and excessive values are clamped. The knob controls the amount of stretch applied. Connections Inputs Index Name Type Desc 0 (none) img (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"contrast stretch"},{"location":"autodocs/contrast_stretch/#contrast-stretch","text":"","title":"contrast stretch"},{"location":"autodocs/contrast_stretch/#description","text":"Perform a simple contrast stretch separately on each channel. The stretch is linear around the midpoint and excessive values are clamped. The knob controls the amount of stretch applied.","title":"Description"},{"location":"autodocs/contrast_stretch/#connections","text":"","title":"Connections"},{"location":"autodocs/contrast_stretch/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/contrast_stretch/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/croproi/","text":"croproi Description Crops an image to a rectangle which is the union of its regions of interest Connections Inputs Index Name Type Desc 0 (none) img (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"croproi"},{"location":"autodocs/croproi/#croproi","text":"","title":"croproi"},{"location":"autodocs/croproi/#description","text":"Crops an image to a rectangle which is the union of its regions of interest","title":"Description"},{"location":"autodocs/croproi/#connections","text":"","title":"Connections"},{"location":"autodocs/croproi/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/croproi/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/crosscalib/","text":"crosscalib Description \"Cross-calibrate\" two images: given points S in a source image and corresponding points D in a destination image, find a vector of factors v for the bands such that S=vD, and transform S accordingly. Essentially, and crudely speaking, make the colours in S match those in D by sampling the same points in each. Connections Inputs Index Name Type Desc 0 source img (none) 1 dest img (none) Outputs Index Name Type Desc 0 out img (none)","title":"crosscalib"},{"location":"autodocs/crosscalib/#crosscalib","text":"","title":"crosscalib"},{"location":"autodocs/crosscalib/#description","text":"\"Cross-calibrate\" two images: given points S in a source image and corresponding points D in a destination image, find a vector of factors v for the bands such that S=vD, and transform S accordingly. Essentially, and crudely speaking, make the colours in S match those in D by sampling the same points in each.","title":"Description"},{"location":"autodocs/crosscalib/#connections","text":"","title":"Connections"},{"location":"autodocs/crosscalib/#inputs","text":"Index Name Type Desc 0 source img (none) 1 dest img (none)","title":"Inputs"},{"location":"autodocs/crosscalib/#outputs","text":"Index Name Type Desc 0 out img (none)","title":"Outputs"},{"location":"autodocs/curve/","text":"curve Description Maps the image channel intensities to a logistic sigmoid curve, y=1/(1+e^-(ax+b)), where a is \"mul\" and b is \"add\". Honours regions of interest. Connections Inputs Index Name Type Desc 0 (none) img (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"curve"},{"location":"autodocs/curve/#curve","text":"","title":"curve"},{"location":"autodocs/curve/#description","text":"Maps the image channel intensities to a logistic sigmoid curve, y=1/(1+e^-(ax+b)), where a is \"mul\" and b is \"add\". Honours regions of interest.","title":"Description"},{"location":"autodocs/curve/#connections","text":"","title":"Connections"},{"location":"autodocs/curve/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/curve/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/decorr_stretch/","text":"decorr stretch Description Perform a decorrelation stretch on an RGB image Connections Inputs Index Name Type Desc 0 rgb img (none) Outputs Index Name Type Desc 0 rgb img (none)","title":"decorr stretch"},{"location":"autodocs/decorr_stretch/#decorr-stretch","text":"","title":"decorr stretch"},{"location":"autodocs/decorr_stretch/#description","text":"Perform a decorrelation stretch on an RGB image","title":"Description"},{"location":"autodocs/decorr_stretch/#connections","text":"","title":"Connections"},{"location":"autodocs/decorr_stretch/#inputs","text":"Index Name Type Desc 0 rgb img (none)","title":"Inputs"},{"location":"autodocs/decorr_stretch/#outputs","text":"Index Name Type Desc 0 rgb img (none)","title":"Outputs"},{"location":"autodocs/dummy/","text":"dummy Description A dummy node type used when the node type specified in a loaded file cannot be found - perhaps it is from an older PCOT version and is now deprecated, or it's part of a plugin? Connections","title":"dummy"},{"location":"autodocs/dummy/#dummy","text":"","title":"dummy"},{"location":"autodocs/dummy/#description","text":"A dummy node type used when the node type specified in a loaded file cannot be found - perhaps it is from an older PCOT version and is now deprecated, or it's part of a plugin?","title":"Description"},{"location":"autodocs/dummy/#connections","text":"","title":"Connections"},{"location":"autodocs/dump/","text":"dump Description Simple data dump: prints a string of its output into its window. Useful for outputting spectra as CSV. Connections Inputs Index Name Type Desc 0 any any (none)","title":"dump"},{"location":"autodocs/dump/#dump","text":"","title":"dump"},{"location":"autodocs/dump/#description","text":"Simple data dump: prints a string of its output into its window. Useful for outputting spectra as CSV.","title":"Description"},{"location":"autodocs/dump/#connections","text":"","title":"Connections"},{"location":"autodocs/dump/#inputs","text":"Index Name Type Desc 0 any any (none)","title":"Inputs"},{"location":"autodocs/expr/","text":"expr Description Expression evaluator. The node box will show the text of the expression. The \"run\" button must be clicked to set the node to the new expression and perform it. Additionally, the output type must be set - the system cannot determine the output type from the input types. The four inputs are assigned to the variables a, b, c, and d. They are typically (but not necessarily) images or scalar values. The standard operators +,/,*,- and ^ all have their usual meanings. When applied to images they work in a pixel-wise fashion, so if a is an image, 2*a will double the brightness. If b is also an image, a+b will add the two images, pixel by pixel. There are two non-standard operators: . for properties and $ for band extraction. These are described below. Image/numeric operators: operator description precedence (higher binds tighter) + add [r] 10 - subtract [r] 10 / divide [r] 20 * multiply [r] 20 ^ exponentiate [r] 30 -A element-wise -A 50 A.B property B of entity A (e.g. a.h is height of image a) 80 A$546 extract single channel image of wavelength 546 100 A&B element-wise minimum of A and B (Zadeh's AND operator) 20 A|B element-wise maximum of A and B (Zadeh's OR operator) 20 !A element-wise 1-A (Zadeh's NOT operator) 50 All operators can act on images and scalars (numeric values), with the exception of . and $ which have images on the left-hand side and identifiers or integers on the right-hand side. Those operators marked with [r] can also act on pairs of ROIs (regions of interest, see below). Binary operations on image pairs These act by performing the binary operation on the two underlying Numpy arrays. This means you may need to be careful about the ordering of the bands in the two images, because they will simply be operated on in the order they appear. For example, consider adding two images $a$ and $b$ with the same bands in a slightly different order: image a image b result of addition 480nm 480nm sum of 480nm bands 500nm 500nm sum of 500nm bands 610nm 670nm a 's 610nm band plus b 's 670nm band 670nm 610nm copy of previous band (addition being commutative) This probably isn't what you wanted. Note that this is obviously not an issue when an operation is being performed on bands in a single image. binary operators on images with regions of interest If one of the two images has an ROI, the operation is only performed on that ROI; the remaining area of output is taken from the image without an ROI. If both images have an ROI an error will result - it is likely that this is a mistake on the user's part, and doing something more \"intelligent\" might conceal this. The desired result can be achieved using expr nodes on ROIs and an importroi node. Operators on ROIs themselves (as opposed to images with ROIs) operator description a+b union a*b intersection a-b difference You can source ROIs from the \"roi\" output of ROI nodes, and impose resulting ROIs on images with \"importroi\" node. Band extraction The notation $name or $wavelength takes an image on the left-hand side and extracts a single band, generating a new monochrome image. The right-hand side is either a filter name, a filter position or a wavelength. Depending on the camera, all these could be valid: expression meaning a$780 the 780nm band in image a (a+b)$G0 the band named G0 in the image formed by adding images a and b ((a+b)/2)$780 the average of the 780nm bands of images a and b Be aware of caveats in the \"binary operations on image pairs\" section above: it may be better to extract the band before performing the operation, thus: old expression better expression (a+b)$G0 a$G0 + b$G0 ((a+b)/2)$780 (a$780+b$780)/2 Properties Properties are indicated by the . operator, e.g. a.w to find an image's width. Help on functions and properties A list of functions can be obtained by right-clicking on either the log pane or function entry pane and selecting \"List all functions.\" Help on an individual function can be found by hovering over the name of a function, right-clicking and selecting \"Get help on 'somefunction'\". Similar actions are supported for properties. Connections Inputs Index Name Type Desc 0 a any (none) 1 b any (none) 2 c any (none) 3 d any (none) Outputs Index Name Type Desc 0 (none) none (none)","title":"expr"},{"location":"autodocs/expr/#expr","text":"","title":"expr"},{"location":"autodocs/expr/#description","text":"Expression evaluator. The node box will show the text of the expression. The \"run\" button must be clicked to set the node to the new expression and perform it. Additionally, the output type must be set - the system cannot determine the output type from the input types. The four inputs are assigned to the variables a, b, c, and d. They are typically (but not necessarily) images or scalar values. The standard operators +,/,*,- and ^ all have their usual meanings. When applied to images they work in a pixel-wise fashion, so if a is an image, 2*a will double the brightness. If b is also an image, a+b will add the two images, pixel by pixel. There are two non-standard operators: . for properties and $ for band extraction. These are described below.","title":"Description"},{"location":"autodocs/expr/#connections","text":"","title":"Connections"},{"location":"autodocs/expr/#inputs","text":"Index Name Type Desc 0 a any (none) 1 b any (none) 2 c any (none) 3 d any (none)","title":"Inputs"},{"location":"autodocs/expr/#outputs","text":"Index Name Type Desc 0 (none) none (none)","title":"Outputs"},{"location":"autodocs/gradient/","text":"gradient Description Convert a greyscale image to an RGB gradient image for better visibility. The gradient widget has the following behaviour: click and drag to move a colour point doubleclick to delete an existing colour point doubleclick to add a new colour point right click to edit an existing colour point Connections Inputs Index Name Type Desc 0 (none) img (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"gradient"},{"location":"autodocs/gradient/#gradient","text":"","title":"gradient"},{"location":"autodocs/gradient/#description","text":"Convert a greyscale image to an RGB gradient image for better visibility. The gradient widget has the following behaviour: click and drag to move a colour point doubleclick to delete an existing colour point doubleclick to add a new colour point right click to edit an existing colour point","title":"Description"},{"location":"autodocs/gradient/#connections","text":"","title":"Connections"},{"location":"autodocs/gradient/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/gradient/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/histequal/","text":"histequal Description Perform histogram equalisation on all channels of the image separately. Honours ROIs. Currently set to 2000 bins, but I may add a control for that. Connections Inputs Index Name Type Desc 0 (none) img (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"histequal"},{"location":"autodocs/histequal/#histequal","text":"","title":"histequal"},{"location":"autodocs/histequal/#description","text":"Perform histogram equalisation on all channels of the image separately. Honours ROIs. Currently set to 2000 bins, but I may add a control for that.","title":"Description"},{"location":"autodocs/histequal/#connections","text":"","title":"Connections"},{"location":"autodocs/histequal/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/histequal/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/histogram/","text":"histogram Description Produce a histogram of intensities for each channel in the data - will be very messy if used on a multispectral image. Connections Inputs Index Name Type Desc 0 (none) img (none)","title":"histogram"},{"location":"autodocs/histogram/#histogram","text":"","title":"histogram"},{"location":"autodocs/histogram/#description","text":"Produce a histogram of intensities for each channel in the data - will be very messy if used on a multispectral image.","title":"Description"},{"location":"autodocs/histogram/#connections","text":"","title":"Connections"},{"location":"autodocs/histogram/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/importroi/","text":"importroi Description Import a ROI into an image which was originally set on another image. The 'roi' input takes either an ROI or an image. If the former, that ROI is imposed on the image passed into the main input. If the latter, all the ROIs from the 'roi' input image are imposed on the image input image. Connections Inputs Index Name Type Desc 0 (none) img (none) 1 roi any (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"importroi"},{"location":"autodocs/importroi/#importroi","text":"","title":"importroi"},{"location":"autodocs/importroi/#description","text":"Import a ROI into an image which was originally set on another image. The 'roi' input takes either an ROI or an image. If the former, that ROI is imposed on the image passed into the main input. If the latter, all the ROIs from the 'roi' input image are imposed on the image input image.","title":"Description"},{"location":"autodocs/importroi/#connections","text":"","title":"Connections"},{"location":"autodocs/importroi/#inputs","text":"Index Name Type Desc 0 (none) img (none) 1 roi any (none)","title":"Inputs"},{"location":"autodocs/importroi/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/in/","text":"in Description The macro input connector (used inside macro prototypes) Connections Outputs Index Name Type Desc 0 (none) variant (none)","title":"in"},{"location":"autodocs/in/#in","text":"","title":"in"},{"location":"autodocs/in/#description","text":"The macro input connector (used inside macro prototypes)","title":"Description"},{"location":"autodocs/in/#connections","text":"","title":"Connections"},{"location":"autodocs/in/#outputs","text":"Index Name Type Desc 0 (none) variant (none)","title":"Outputs"},{"location":"autodocs/input_0/","text":"input 0 Description Imports Input 0's data into the graph Connections Outputs Index Name Type Desc 0 img img image","title":"input 0"},{"location":"autodocs/input_0/#input-0","text":"","title":"input 0"},{"location":"autodocs/input_0/#description","text":"Imports Input 0's data into the graph","title":"Description"},{"location":"autodocs/input_0/#connections","text":"","title":"Connections"},{"location":"autodocs/input_0/#outputs","text":"Index Name Type Desc 0 img img image","title":"Outputs"},{"location":"autodocs/input_1/","text":"input 1 Description Imports Input 1's data into the graph Connections Outputs Index Name Type Desc 0 img img image","title":"input 1"},{"location":"autodocs/input_1/#input-1","text":"","title":"input 1"},{"location":"autodocs/input_1/#description","text":"Imports Input 1's data into the graph","title":"Description"},{"location":"autodocs/input_1/#connections","text":"","title":"Connections"},{"location":"autodocs/input_1/#outputs","text":"Index Name Type Desc 0 img img image","title":"Outputs"},{"location":"autodocs/input_2/","text":"input 2 Description Imports Input 2's data into the graph Connections Outputs Index Name Type Desc 0 img img image","title":"input 2"},{"location":"autodocs/input_2/#input-2","text":"","title":"input 2"},{"location":"autodocs/input_2/#description","text":"Imports Input 2's data into the graph","title":"Description"},{"location":"autodocs/input_2/#connections","text":"","title":"Connections"},{"location":"autodocs/input_2/#outputs","text":"Index Name Type Desc 0 img img image","title":"Outputs"},{"location":"autodocs/input_3/","text":"input 3 Description Imports Input 3's data into the graph Connections Outputs Index Name Type Desc 0 img img image","title":"input 3"},{"location":"autodocs/input_3/#input-3","text":"","title":"input 3"},{"location":"autodocs/input_3/#description","text":"Imports Input 3's data into the graph","title":"Description"},{"location":"autodocs/input_3/#connections","text":"","title":"Connections"},{"location":"autodocs/input_3/#outputs","text":"Index Name Type Desc 0 img img image","title":"Outputs"},{"location":"autodocs/inset/","text":"inset Description Inset an image inside another. Uses RGB versions of both images, as defined by the RGB mapping set in the previous nodes. Does not honour regions of interest. Note that there is no RGB mapping in the canvas for the tab - RGB mappings should be set in the input nodes. Connections Inputs Index Name Type Desc 0 img img (none) 1 inset img (none) 2 roi roi (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"inset"},{"location":"autodocs/inset/#inset","text":"","title":"inset"},{"location":"autodocs/inset/#description","text":"Inset an image inside another. Uses RGB versions of both images, as defined by the RGB mapping set in the previous nodes. Does not honour regions of interest. Note that there is no RGB mapping in the canvas for the tab - RGB mappings should be set in the input nodes.","title":"Description"},{"location":"autodocs/inset/#connections","text":"","title":"Connections"},{"location":"autodocs/inset/#inputs","text":"Index Name Type Desc 0 img img (none) 1 inset img (none) 2 roi roi (none)","title":"Inputs"},{"location":"autodocs/inset/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/manual_register/","text":"manual register Description Perform manual registration of two images. The output is a version of the 'moving' image with a projective transform applied to map points onto corresponding points in the 'fixed' image. The canvas view can show the moving input (also referred to as the \"source\"), the fixed image (also referred to as the \"destination\"), a blend of the two, or the result. All images are shown as greyscale (since the fixed and moving images will likely have different frequency bands). The transform will map a set of points in the moving image onto a set in the fixed image. Both sets of points can be changed, or a single set. Points are mapped onto the correspondingly numbered point. In \"translate\" mode only a single point is required (and only a single point will be shown from each set). Points are added to the source (moving) image by clicking with shift. Points are adding to the dest (fixed) image by clicking with ctrl. If only the source or dest points are shown, either shift- or ctrl-clicking will add to the appropriate point set. The selected point can be deleted with the Delete key (but this will modify the numbering!) A point can be selected and dragged by clicking on it. This may be slow because the warping operation will take place every update; disabling 'auto-run on change' is a good idea! Connections Inputs Index Name Type Desc 0 moving img (none) 1 fixed img (none) Outputs Index Name Type Desc 0 moved img (none)","title":"manual register"},{"location":"autodocs/manual_register/#manual-register","text":"","title":"manual register"},{"location":"autodocs/manual_register/#description","text":"Perform manual registration of two images. The output is a version of the 'moving' image with a projective transform applied to map points onto corresponding points in the 'fixed' image. The canvas view can show the moving input (also referred to as the \"source\"), the fixed image (also referred to as the \"destination\"), a blend of the two, or the result. All images are shown as greyscale (since the fixed and moving images will likely have different frequency bands). The transform will map a set of points in the moving image onto a set in the fixed image. Both sets of points can be changed, or a single set. Points are mapped onto the correspondingly numbered point. In \"translate\" mode only a single point is required (and only a single point will be shown from each set). Points are added to the source (moving) image by clicking with shift. Points are adding to the dest (fixed) image by clicking with ctrl. If only the source or dest points are shown, either shift- or ctrl-clicking will add to the appropriate point set. The selected point can be deleted with the Delete key (but this will modify the numbering!) A point can be selected and dragged by clicking on it. This may be slow because the warping operation will take place every update; disabling 'auto-run on change' is a good idea!","title":"Description"},{"location":"autodocs/manual_register/#connections","text":"","title":"Connections"},{"location":"autodocs/manual_register/#inputs","text":"Index Name Type Desc 0 moving img (none) 1 fixed img (none)","title":"Inputs"},{"location":"autodocs/manual_register/#outputs","text":"Index Name Type Desc 0 moved img (none)","title":"Outputs"},{"location":"autodocs/multidot/","text":"multidot Description Add multiple small circle ROIs. Most subsequent operations will only be performed on the union of all regions of interest. Also outputs an RGB image annotated with the ROIs on the 'ann' RGB input, or the input image converted to RGB if that input is not connected. Note that this type doesn't inherit from XFormROI Connections Inputs Index Name Type Desc 0 input img (none) 1 ann imgrgb used as base for annotated image Outputs Index Name Type Desc 0 img img image with ROIs 1 ann imgrgb image as RGB with ROIs, with added annotations around ROIs","title":"multidot"},{"location":"autodocs/multidot/#multidot","text":"","title":"multidot"},{"location":"autodocs/multidot/#description","text":"Add multiple small circle ROIs. Most subsequent operations will only be performed on the union of all regions of interest. Also outputs an RGB image annotated with the ROIs on the 'ann' RGB input, or the input image converted to RGB if that input is not connected. Note that this type doesn't inherit from XFormROI","title":"Description"},{"location":"autodocs/multidot/#connections","text":"","title":"Connections"},{"location":"autodocs/multidot/#inputs","text":"Index Name Type Desc 0 input img (none) 1 ann imgrgb used as base for annotated image","title":"Inputs"},{"location":"autodocs/multidot/#outputs","text":"Index Name Type Desc 0 img img image with ROIs 1 ann imgrgb image as RGB with ROIs, with added annotations around ROIs","title":"Outputs"},{"location":"autodocs/normimage/","text":"normimage Description Normalise the image to a single range taken from all channels. Honours ROIs. If you need to normalise each channel separately, use the norm() function in the \"expr\" node which has an optional argument for this. Connections Inputs Index Name Type Desc 0 (none) img (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"normimage"},{"location":"autodocs/normimage/#normimage","text":"","title":"normimage"},{"location":"autodocs/normimage/#description","text":"Normalise the image to a single range taken from all channels. Honours ROIs. If you need to normalise each channel separately, use the norm() function in the \"expr\" node which has an optional argument for this.","title":"Description"},{"location":"autodocs/normimage/#connections","text":"","title":"Connections"},{"location":"autodocs/normimage/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/normimage/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/offset/","text":"offset Description offset an image. Will create a zero band on one edge and clip on the opposite. ROIs are not honoured, but are passed through. Connections Inputs Index Name Type Desc 0 (none) img (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"offset"},{"location":"autodocs/offset/#offset","text":"","title":"offset"},{"location":"autodocs/offset/#description","text":"offset an image. Will create a zero band on one edge and clip on the opposite. ROIs are not honoured, but are passed through.","title":"Description"},{"location":"autodocs/offset/#connections","text":"","title":"Connections"},{"location":"autodocs/offset/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/offset/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/out/","text":"out Description The macro output connector (used inside macro prototypes) Connections Inputs Index Name Type Desc 0 (none) variant (none)","title":"out"},{"location":"autodocs/out/#out","text":"","title":"out"},{"location":"autodocs/out/#description","text":"The macro output connector (used inside macro prototypes)","title":"Description"},{"location":"autodocs/out/#connections","text":"","title":"Connections"},{"location":"autodocs/out/#inputs","text":"Index Name Type Desc 0 (none) variant (none)","title":"Inputs"},{"location":"autodocs/painted/","text":"painted Description Add a painted ROI to an image. Most subsequent operations will only be performed on the union of all regions of interest. Also outputs an RGB image annotated with the ROI on the 'ann' RGB input, or the input image converted to RGB if that input is not connected. Connections Inputs Index Name Type Desc 0 input img (none) 1 ann imgrgb used as base for annotated image Outputs Index Name Type Desc 0 img img image with ROI 1 ann imgrgb image as RGB with ROI, with added annotations around ROI 2 roi roi the region of interest","title":"painted"},{"location":"autodocs/painted/#painted","text":"","title":"painted"},{"location":"autodocs/painted/#description","text":"Add a painted ROI to an image. Most subsequent operations will only be performed on the union of all regions of interest. Also outputs an RGB image annotated with the ROI on the 'ann' RGB input, or the input image converted to RGB if that input is not connected.","title":"Description"},{"location":"autodocs/painted/#connections","text":"","title":"Connections"},{"location":"autodocs/painted/#inputs","text":"Index Name Type Desc 0 input img (none) 1 ann imgrgb used as base for annotated image","title":"Inputs"},{"location":"autodocs/painted/#outputs","text":"Index Name Type Desc 0 img img image with ROI 1 ann imgrgb image as RGB with ROI, with added annotations around ROI 2 roi roi the region of interest","title":"Outputs"},{"location":"autodocs/pct/","text":"pct Description Locates the PCT and generates calibration coefficients Connections Inputs Index Name Type Desc 0 img img (none)","title":"pct"},{"location":"autodocs/pct/#pct","text":"","title":"pct"},{"location":"autodocs/pct/#description","text":"Locates the PCT and generates calibration coefficients","title":"Description"},{"location":"autodocs/pct/#connections","text":"","title":"Connections"},{"location":"autodocs/pct/#inputs","text":"Index Name Type Desc 0 img img (none)","title":"Inputs"},{"location":"autodocs/poly/","text":"poly Description Add a polygonal ROI to an image. Most subsequent operations will only be performed on the union of all regions of interest. Also outputs an RGB image annotated with the ROI on the 'ann' RGB input, or the input image converted to RGB if that input is not connected. Connections Inputs Index Name Type Desc 0 input img (none) 1 ann imgrgb used as base for annotated image Outputs Index Name Type Desc 0 img img image with ROI 1 ann imgrgb image as RGB with ROI, with added annotations around ROI 2 roi roi the region of interest","title":"poly"},{"location":"autodocs/poly/#poly","text":"","title":"poly"},{"location":"autodocs/poly/#description","text":"Add a polygonal ROI to an image. Most subsequent operations will only be performed on the union of all regions of interest. Also outputs an RGB image annotated with the ROI on the 'ann' RGB input, or the input image converted to RGB if that input is not connected.","title":"Description"},{"location":"autodocs/poly/#connections","text":"","title":"Connections"},{"location":"autodocs/poly/#inputs","text":"Index Name Type Desc 0 input img (none) 1 ann imgrgb used as base for annotated image","title":"Inputs"},{"location":"autodocs/poly/#outputs","text":"Index Name Type Desc 0 img img image with ROI 1 ann imgrgb image as RGB with ROI, with added annotations around ROI 2 roi roi the region of interest","title":"Outputs"},{"location":"autodocs/rect/","text":"rect Description Add a rectangular ROI to an image. Most subsequent operations will only be performed on the union of all regions of interest. Also outputs an RGB image annotated with the ROI on the 'ann' RGB input, or the input image converted to RGB if that input is not connected. Connections Inputs Index Name Type Desc 0 input img (none) 1 ann imgrgb used as base for annotated image Outputs Index Name Type Desc 0 img img image with ROI 1 ann imgrgb image as RGB with ROI, with added annotations around ROI 2 roi roi the region of interest","title":"rect"},{"location":"autodocs/rect/#rect","text":"","title":"rect"},{"location":"autodocs/rect/#description","text":"Add a rectangular ROI to an image. Most subsequent operations will only be performed on the union of all regions of interest. Also outputs an RGB image annotated with the ROI on the 'ann' RGB input, or the input image converted to RGB if that input is not connected.","title":"Description"},{"location":"autodocs/rect/#connections","text":"","title":"Connections"},{"location":"autodocs/rect/#inputs","text":"Index Name Type Desc 0 input img (none) 1 ann imgrgb used as base for annotated image","title":"Inputs"},{"location":"autodocs/rect/#outputs","text":"Index Name Type Desc 0 img img image with ROI 1 ann imgrgb image as RGB with ROI, with added annotations around ROI 2 roi roi the region of interest","title":"Outputs"},{"location":"autodocs/show_number/","text":"show number Description Display a numeric value inside the node's box in the graph Connections Inputs Index Name Type Desc 0 (none) number (none)","title":"show number"},{"location":"autodocs/show_number/#show-number","text":"","title":"show number"},{"location":"autodocs/show_number/#description","text":"Display a numeric value inside the node's box in the graph","title":"Description"},{"location":"autodocs/show_number/#connections","text":"","title":"Connections"},{"location":"autodocs/show_number/#inputs","text":"Index Name Type Desc 0 (none) number (none)","title":"Inputs"},{"location":"autodocs/sink/","text":"sink Description Simply view an image. Connections Inputs Index Name Type Desc 0 (none) any (none)","title":"sink"},{"location":"autodocs/sink/#sink","text":"","title":"sink"},{"location":"autodocs/sink/#description","text":"Simply view an image.","title":"Description"},{"location":"autodocs/sink/#connections","text":"","title":"Connections"},{"location":"autodocs/sink/#inputs","text":"Index Name Type Desc 0 (none) any (none)","title":"Inputs"},{"location":"autodocs/spectrum/","text":"spectrum Description Show the mean intensities for each frequency band in each input. Each input has a separate line in the resulting plot, labelled with either a generated label or the annotation of the last ROI on that input. If two inputs have the same ROI label, they are merged into a single line. Connections Inputs Index Name Type Desc 0 0 img a single line in the plot 1 1 img a single line in the plot 2 2 img a single line in the plot 3 3 img a single line in the plot 4 4 img a single line in the plot 5 5 img a single line in the plot 6 6 img a single line in the plot 7 7 img a single line in the plot Outputs Index Name Type Desc 0 data data a CSV output (use 'dump' to read it)","title":"spectrum"},{"location":"autodocs/spectrum/#spectrum","text":"","title":"spectrum"},{"location":"autodocs/spectrum/#description","text":"Show the mean intensities for each frequency band in each input. Each input has a separate line in the resulting plot, labelled with either a generated label or the annotation of the last ROI on that input. If two inputs have the same ROI label, they are merged into a single line.","title":"Description"},{"location":"autodocs/spectrum/#connections","text":"","title":"Connections"},{"location":"autodocs/spectrum/#inputs","text":"Index Name Type Desc 0 0 img a single line in the plot 1 1 img a single line in the plot 2 2 img a single line in the plot 3 3 img a single line in the plot 4 4 img a single line in the plot 5 5 img a single line in the plot 6 6 img a single line in the plot 7 7 img a single line in the plot","title":"Inputs"},{"location":"autodocs/spectrum/#outputs","text":"Index Name Type Desc 0 data data a CSV output (use 'dump' to read it)","title":"Outputs"},{"location":"autodocs/stitch/","text":"stitch Description This node performs manual stitching of multiple images into a single image. Connections Inputs Index Name Type Desc 0 0 img Input image 0 1 1 img Input image 1 2 2 img Input image 2 3 3 img Input image 3 4 4 img Input image 4 5 5 img Input image 5 6 6 img Input image 6 7 7 img Input image 7 Outputs Index Name Type Desc 0 (none) img Output image","title":"stitch"},{"location":"autodocs/stitch/#stitch","text":"","title":"stitch"},{"location":"autodocs/stitch/#description","text":"This node performs manual stitching of multiple images into a single image.","title":"Description"},{"location":"autodocs/stitch/#connections","text":"","title":"Connections"},{"location":"autodocs/stitch/#inputs","text":"Index Name Type Desc 0 0 img Input image 0 1 1 img Input image 1 2 2 img Input image 2 3 3 img Input image 3 4 4 img Input image 4 5 5 img Input image 5 6 6 img Input image 6 7 7 img Input image 7","title":"Inputs"},{"location":"autodocs/stitch/#outputs","text":"Index Name Type Desc 0 (none) img Output image","title":"Outputs"},{"location":"autodocs/striproi/","text":"striproi Description Strip ROIs from an image Connections Inputs Index Name Type Desc 0 (none) img (none) Outputs Index Name Type Desc 0 (none) img (none)","title":"striproi"},{"location":"autodocs/striproi/#striproi","text":"","title":"striproi"},{"location":"autodocs/striproi/#description","text":"Strip ROIs from an image","title":"Description"},{"location":"autodocs/striproi/#connections","text":"","title":"Connections"},{"location":"autodocs/striproi/#inputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Inputs"},{"location":"autodocs/striproi/#outputs","text":"Index Name Type Desc 0 (none) img (none)","title":"Outputs"},{"location":"autodocs/tvl1_autoreg/","text":"tvl1 autoreg Description Use the TV-L1 solver to find an optical flow field for transforming one image into another. Not generally advised, and very slow. The node will output a version of the 'moving' image, distorted to map onto the 'fixed' image. Connections Inputs Index Name Type Desc 0 moving img (none) 1 fixed img (none) Outputs Index Name Type Desc 0 moved img (none)","title":"tvl1 autoreg"},{"location":"autodocs/tvl1_autoreg/#tvl1-autoreg","text":"","title":"tvl1 autoreg"},{"location":"autodocs/tvl1_autoreg/#description","text":"Use the TV-L1 solver to find an optical flow field for transforming one image into another. Not generally advised, and very slow. The node will output a version of the 'moving' image, distorted to map onto the 'fixed' image.","title":"Description"},{"location":"autodocs/tvl1_autoreg/#connections","text":"","title":"Connections"},{"location":"autodocs/tvl1_autoreg/#inputs","text":"Index Name Type Desc 0 moving img (none) 1 fixed img (none)","title":"Inputs"},{"location":"autodocs/tvl1_autoreg/#outputs","text":"Index Name Type Desc 0 moved img (none)","title":"Outputs"},{"location":"devguide/","text":"Overview These pages describe how to develop plugins for PCOT and use PCOT as a library, and also various internal developer notes. Contents Using PCOT as a library Developing plugins Miscellaneous notes on type internals and adding new types . test/scratchpad of LaTeX support .","title":"Overview"},{"location":"devguide/#overview","text":"These pages describe how to develop plugins for PCOT and use PCOT as a library, and also various internal developer notes.","title":"Overview"},{"location":"devguide/#contents","text":"","title":"Contents"},{"location":"devguide/#using-pcot-as-a-library","text":"","title":"Using PCOT as a library"},{"location":"devguide/#developing-plugins","text":"","title":"Developing plugins"},{"location":"devguide/#miscellaneous","text":"notes on type internals and adding new types . test/scratchpad of LaTeX support .","title":"Miscellaneous"},{"location":"devguide/latex/","text":"A quick test of LaTeX support LaTeX in these documents is handled with the pymdownx.arithmatex plugin, which really just hands processing off to MathJax. MathJax then renders the LaTeX using JavaScript. Lots and lots of very clever JavaScript. Here are some tests: Inline equation: y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right) y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right) should work. Inline equation: $y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right)$ should work. Block equations. This has to use double-backslash: \\[ y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right) \\] \\\\[ y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right) \\\\] but this one doesn't: \\begin{equation} f(1,0)=1 \\iff w_1 \\ge -b \\label{eq:f101} \\end{equation} \\begin{equation} f(1,0)=1 \\iff w_1 \\ge -b \\label{eq:f101} \\end{equation} \\begin{equation} f(1,0)=1 \\iff w_1 \\ge -b \\label{eq:f101} \\end{equation} Align. Note that the reference doesn't work! \\begin{align} f(x,y) &= H (b+w_1 x + w_2 y)&\\text{(Eq.~\\ref{eq:f101})}\\\\ 0 &= H(b+w_1+w_2)&\\text{(subst.)}\\\\ H(b+w_1+w_2) &= 0\\label{eq:f110in}\\\\ b+w_1+w_2 & < 0 & \\text{(Heaviside step)}\\\\ w_1+w_2 & < -b. \\end{align} \\begin{align} f(x,y) &= H (b+w_1 x + w_2 y)&\\text{(Eq.~\\ref{eq:f101})}\\\\ 0 &= H(b+w_1+w_2)&\\text{(subst.)}\\\\ H(b+w_1+w_2) &= 0\\label{eq:f110in}\\\\ b+w_1+w_2 & < 0 & \\text{(Heaviside step)}\\\\ w_1+w_2 & < -b. \\end{align} \\begin{align} f(x,y) &= H (b+w_1 x + w_2 y)&\\text{(Eq.~\\ref{eq:f101})}\\\\ 0 &= H(b+w_1+w_2)&\\text{(subst.)}\\\\ H(b+w_1+w_2) &= 0\\label{eq:f110in}\\\\ b+w_1+w_2 & < 0 & \\text{(Heaviside step)}\\\\ w_1+w_2 & < -b. \\end{align} Matrix. Note I've had to wrap in an equation. \\begin{equation} X= \\left(\\begin{matrix} 1 & 2 & 1\\\\ 2 & 4 & 2\\\\ 1 & 2 & 1 \\end{matrix}\\right) \\end{equation} \\begin{equation} X= \\left(\\begin{matrix} 1 & 2 & 1\\\\ 2 & 4 & 2\\\\ 1 & 2 & 1 \\end{matrix}\\right) \\end{equation} \\begin{equation} X= \\left(\\begin{matrix} 1 & 2 & 1\\\\ 2 & 4 & 2\\\\ 1 & 2 & 1 \\end{matrix}\\right) \\end{equation}","title":"A quick test of LaTeX support"},{"location":"devguide/latex/#a-quick-test-of-latex-support","text":"LaTeX in these documents is handled with the pymdownx.arithmatex plugin, which really just hands processing off to MathJax. MathJax then renders the LaTeX using JavaScript. Lots and lots of very clever JavaScript. Here are some tests: Inline equation: y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right) y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right) should work. Inline equation: $y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right)$ should work. Block equations. This has to use double-backslash: \\[ y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right) \\] \\\\[ y = \\sigma\\left(b+\\sum_i w_i x_i (1+h) s_i\\right) \\\\] but this one doesn't: \\begin{equation} f(1,0)=1 \\iff w_1 \\ge -b \\label{eq:f101} \\end{equation} \\begin{equation} f(1,0)=1 \\iff w_1 \\ge -b \\label{eq:f101} \\end{equation} \\begin{equation} f(1,0)=1 \\iff w_1 \\ge -b \\label{eq:f101} \\end{equation} Align. Note that the reference doesn't work! \\begin{align} f(x,y) &= H (b+w_1 x + w_2 y)&\\text{(Eq.~\\ref{eq:f101})}\\\\ 0 &= H(b+w_1+w_2)&\\text{(subst.)}\\\\ H(b+w_1+w_2) &= 0\\label{eq:f110in}\\\\ b+w_1+w_2 & < 0 & \\text{(Heaviside step)}\\\\ w_1+w_2 & < -b. \\end{align} \\begin{align} f(x,y) &= H (b+w_1 x + w_2 y)&\\text{(Eq.~\\ref{eq:f101})}\\\\ 0 &= H(b+w_1+w_2)&\\text{(subst.)}\\\\ H(b+w_1+w_2) &= 0\\label{eq:f110in}\\\\ b+w_1+w_2 & < 0 & \\text{(Heaviside step)}\\\\ w_1+w_2 & < -b. \\end{align} \\begin{align} f(x,y) &= H (b+w_1 x + w_2 y)&\\text{(Eq.~\\ref{eq:f101})}\\\\ 0 &= H(b+w_1+w_2)&\\text{(subst.)}\\\\ H(b+w_1+w_2) &= 0\\label{eq:f110in}\\\\ b+w_1+w_2 & < 0 & \\text{(Heaviside step)}\\\\ w_1+w_2 & < -b. \\end{align} Matrix. Note I've had to wrap in an equation. \\begin{equation} X= \\left(\\begin{matrix} 1 & 2 & 1\\\\ 2 & 4 & 2\\\\ 1 & 2 & 1 \\end{matrix}\\right) \\end{equation} \\begin{equation} X= \\left(\\begin{matrix} 1 & 2 & 1\\\\ 2 & 4 & 2\\\\ 1 & 2 & 1 \\end{matrix}\\right) \\end{equation} \\begin{equation} X= \\left(\\begin{matrix} 1 & 2 & 1\\\\ 2 & 4 & 2\\\\ 1 & 2 & 1 \\end{matrix}\\right) \\end{equation}","title":"A quick test of LaTeX support"},{"location":"devguide/types/","text":"Notes on types Built-in types of data (i.e. of Datum objects) are kept in datum.py . A type specifies: its name whether it is an image subtype (it's tricky to write a method for this, since ImgType is defined after Type) whether it is an \"internal type\" used in the expression evaluator and not for connections (e.g. IdentType, FuncType and NoneType) optional serialisation and deserialisation methods, taking and returning Datum The Datum class has a type list, which contains singletons of all the type objects. To register a type: create a type object append to the Datum types list if required, register a connector brush with connbrushes.register. Deal with binary and unary operators in expr expressions (see below). Operators Work in progress Previously operators were entirely hardwired in utils.ops. This stopped us creating new types. We could define something like binop(self,other) in the type classes, but this wouldn't allow us to add new types as the RHS for operations which have built-in types as the LHS. The Simplest Thing That Can Possibly Work is a dictionary of operation functions keyed (in the case of binops) by a tuple of types. So this is how operators work now, relying on two registration processes. The first is the registration of the operator lexeme (e.g. \"*\" or \"+\") and precedence, and an associated function to call. This happens as part of Parser. The function calls a binop() function in the ops module, passing in the operator ID. The second is the registration of operator ID (e.g. Operator.ADD) and types in the ops module, with an associated function to call. This is often a wrapper function around a lambda: the wrapper knows to unpack (say) image and number data, and the lambda says they should be processed with addition. Adding a new type with operator semantics Create a subclass of datum.Type add serialisation methods if required call Datum.registerType() with the type If required, add a new connector brush with connbrushes.register() To use the type, use the Type object with the Datum constructor and Datum.get() method. Adding operator semantics call ops.registerBinop and ops.registerUnop to register functions to perform the required operations. The function should take Datum objects and return a Datum.","title":"Notes on types"},{"location":"devguide/types/#notes-on-types","text":"Built-in types of data (i.e. of Datum objects) are kept in datum.py . A type specifies: its name whether it is an image subtype (it's tricky to write a method for this, since ImgType is defined after Type) whether it is an \"internal type\" used in the expression evaluator and not for connections (e.g. IdentType, FuncType and NoneType) optional serialisation and deserialisation methods, taking and returning Datum The Datum class has a type list, which contains singletons of all the type objects. To register a type: create a type object append to the Datum types list if required, register a connector brush with connbrushes.register. Deal with binary and unary operators in expr expressions (see below).","title":"Notes on types"},{"location":"devguide/types/#operators","text":"Work in progress Previously operators were entirely hardwired in utils.ops. This stopped us creating new types. We could define something like binop(self,other) in the type classes, but this wouldn't allow us to add new types as the RHS for operations which have built-in types as the LHS. The Simplest Thing That Can Possibly Work is a dictionary of operation functions keyed (in the case of binops) by a tuple of types. So this is how operators work now, relying on two registration processes. The first is the registration of the operator lexeme (e.g. \"*\" or \"+\") and precedence, and an associated function to call. This happens as part of Parser. The function calls a binop() function in the ops module, passing in the operator ID. The second is the registration of operator ID (e.g. Operator.ADD) and types in the ops module, with an associated function to call. This is often a wrapper function around a lambda: the wrapper knows to unpack (say) image and number data, and the lambda says they should be processed with addition.","title":"Operators"},{"location":"devguide/types/#adding-a-new-type-with-operator-semantics","text":"Create a subclass of datum.Type add serialisation methods if required call Datum.registerType() with the type If required, add a new connector brush with connbrushes.register() To use the type, use the Type object with the Datum constructor and Datum.get() method. Adding operator semantics call ops.registerBinop and ops.registerUnop to register functions to perform the required operations. The function should take Datum objects and return a Datum.","title":"Adding a new type with operator semantics"},{"location":"gettingstarted/","text":"Overview This provides a basic introduction to PCOT, telling you how to install it, providing important information on the core concepts behind PCOT, and giving a basic tutorial. Once you have tinkered with PCOT a little the User Guide will provide reference information. How to install and run PCOT Introduction to core PCOT concepts A first tutorial Video guide There is a video guide .","title":"Overview"},{"location":"gettingstarted/#overview","text":"This provides a basic introduction to PCOT, telling you how to install it, providing important information on the core concepts behind PCOT, and giving a basic tutorial. Once you have tinkered with PCOT a little the User Guide will provide reference information. How to install and run PCOT Introduction to core PCOT concepts A first tutorial","title":"Overview"},{"location":"gettingstarted/#video-guide","text":"There is a video guide .","title":"Video guide"},{"location":"gettingstarted/concepts/","text":"Concepts How PCOT works (and why) PCOT is a tool designed to help scientists and engineers analyse PanCam data and produce useful secondary data. It acts downstream from the ROCC on images which have already been processed to some extent, and is a successor to ExoSpec. As such, its primary purpose is to generate relative reflectance images and spectral parameter maps, although it will also be able to produce spectra from small regions of interest. Indeed, it should be flexible enough to perform a wide range of unforeseen calculations. Of paramount importance is the verifiability and reproducibility of data generated from PCOT. To this end, a PCOT document is a data product which can be shared between users, which also fully describes how the data was generated from the initial import to the final output. Users are encouraged to exchange PCOT documents in addition to, or instead of, the generated images or data. The Graph To achieve this, a PCOT document manipulates data in a graph - a network of nodes, each of which takes some data, works on it, perhaps displays some data, and perhaps outputs derived data. Technically speaking, this is a \"directed acyclic graph\": each connection has a direction, going from the output of one node to the input of another, and there can't be any loops. As an example, consider that we might want to overlay some kind of spectral parameter map, converted to a colour gradient, over an RGB image (note: I'm not a geologist, I'm a software engineer, so perhaps this is a very artificial example). One way to do it might be this: Figure: An example graph. Click on image to expand. We can see the graph in the panel on the right, showing each node as a box with connections to other nodes (ignore the green numbers, they just show how many times each node has run - it's a debugging aid!) Here's what each node in the graph is doing: The input 3 node reads input number 3 into the graph. The inputs are set up separately from the graph, and can be multispectral images or other data (e.g. housekeeping) from outside PCOT. The rect node lets the user draw a rectangle on the image to define a region of interest. Images can have many regions of interest and several different kinds are available. The node with 4 inputs a,b,c,d is an expr node, which calculates the result of a mathematical expression performed on each pixel. The node is showing the expression it is running: norm(a$671 / a$438) . This will read the bands whose wavelengths are 671nm and 438nm in the node's a input, and find their ratio for every pixel. It will then normalise the result to the range [0,1]. The result will be a single-band image. Expr nodes can perform much more complex calculations than this. The croproi node will crop that resulting image to its region of interest - the rectangle we added earlier. The gradient node will convert a single-band image into an RGB image with a user-defined gradient. Finally, the inset node will inset this RGB image into an RGB representation of the original image - the mapping of bands in that image onto RGB is done in the input node. A label can be added here. Of course, if you feel the gradient is rather artificial, the inset can just be the original band ratio image expanded to RGB greyscale using another expr node: Figure: Using a greyscale inset. Click on image to expand. Here is another example, showing a spectral plot: The input node again brings a multispectral image into the graph. The multidot node adds a number of small, circular regions of interest. Each has a different name and colour, in this case set automatically to just numbers and random colours. Creating the regions is as easy as clicking on the image. The spectrum node plots a spectrogram of the regions present in the image for all the wavelengths in that image. Figure: Spectrogram example. Click on image to expand. Here I have \"undocked\" the spectrum node's tab to be a separate window for easy viewing. The spectrum can also be saved as a PDF or converted into CSV data. The Document A PCOT document is a file which can be shared among users. It consists of The inputs - data loaded from sources external to PCOT. These are kept separate from the graph, because you might want to use a different graph on the same inputs, or the load the same inputs into a different graph. There are currently up to four inputs, but this can easily be changed. The graph - a set of nodes and connections between them which define operations to be performed on inputs, as shown above. The settings - these are global to the entire application. Macros - these are sets of nodes which can be used multiple times and appear as single nodes in the graph, although each one has its own \"private\" graph. Currently very experimental (and largely undocumented). Important The data being sent out of the inputs into the graph is saved and loaded with the document, so the original source data does not need to be stored - you can send the document to someone and it will still work even if they don't have the sources. Move on to Getting Started","title":"PCOT concepts"},{"location":"gettingstarted/concepts/#concepts","text":"How PCOT works (and why) PCOT is a tool designed to help scientists and engineers analyse PanCam data and produce useful secondary data. It acts downstream from the ROCC on images which have already been processed to some extent, and is a successor to ExoSpec. As such, its primary purpose is to generate relative reflectance images and spectral parameter maps, although it will also be able to produce spectra from small regions of interest. Indeed, it should be flexible enough to perform a wide range of unforeseen calculations. Of paramount importance is the verifiability and reproducibility of data generated from PCOT. To this end, a PCOT document is a data product which can be shared between users, which also fully describes how the data was generated from the initial import to the final output. Users are encouraged to exchange PCOT documents in addition to, or instead of, the generated images or data.","title":"Concepts"},{"location":"gettingstarted/concepts/#the-graph","text":"To achieve this, a PCOT document manipulates data in a graph - a network of nodes, each of which takes some data, works on it, perhaps displays some data, and perhaps outputs derived data. Technically speaking, this is a \"directed acyclic graph\": each connection has a direction, going from the output of one node to the input of another, and there can't be any loops. As an example, consider that we might want to overlay some kind of spectral parameter map, converted to a colour gradient, over an RGB image (note: I'm not a geologist, I'm a software engineer, so perhaps this is a very artificial example). One way to do it might be this: Figure: An example graph. Click on image to expand. We can see the graph in the panel on the right, showing each node as a box with connections to other nodes (ignore the green numbers, they just show how many times each node has run - it's a debugging aid!) Here's what each node in the graph is doing: The input 3 node reads input number 3 into the graph. The inputs are set up separately from the graph, and can be multispectral images or other data (e.g. housekeeping) from outside PCOT. The rect node lets the user draw a rectangle on the image to define a region of interest. Images can have many regions of interest and several different kinds are available. The node with 4 inputs a,b,c,d is an expr node, which calculates the result of a mathematical expression performed on each pixel. The node is showing the expression it is running: norm(a$671 / a$438) . This will read the bands whose wavelengths are 671nm and 438nm in the node's a input, and find their ratio for every pixel. It will then normalise the result to the range [0,1]. The result will be a single-band image. Expr nodes can perform much more complex calculations than this. The croproi node will crop that resulting image to its region of interest - the rectangle we added earlier. The gradient node will convert a single-band image into an RGB image with a user-defined gradient. Finally, the inset node will inset this RGB image into an RGB representation of the original image - the mapping of bands in that image onto RGB is done in the input node. A label can be added here. Of course, if you feel the gradient is rather artificial, the inset can just be the original band ratio image expanded to RGB greyscale using another expr node: Figure: Using a greyscale inset. Click on image to expand. Here is another example, showing a spectral plot: The input node again brings a multispectral image into the graph. The multidot node adds a number of small, circular regions of interest. Each has a different name and colour, in this case set automatically to just numbers and random colours. Creating the regions is as easy as clicking on the image. The spectrum node plots a spectrogram of the regions present in the image for all the wavelengths in that image. Figure: Spectrogram example. Click on image to expand. Here I have \"undocked\" the spectrum node's tab to be a separate window for easy viewing. The spectrum can also be saved as a PDF or converted into CSV data.","title":"The Graph"},{"location":"gettingstarted/concepts/#the-document","text":"A PCOT document is a file which can be shared among users. It consists of The inputs - data loaded from sources external to PCOT. These are kept separate from the graph, because you might want to use a different graph on the same inputs, or the load the same inputs into a different graph. There are currently up to four inputs, but this can easily be changed. The graph - a set of nodes and connections between them which define operations to be performed on inputs, as shown above. The settings - these are global to the entire application. Macros - these are sets of nodes which can be used multiple times and appear as single nodes in the graph, although each one has its own \"private\" graph. Currently very experimental (and largely undocumented). Important The data being sent out of the inputs into the graph is saved and loaded with the document, so the original source data does not need to be stored - you can send the document to someone and it will still work even if they don't have the sources. Move on to Getting Started","title":"The Document"},{"location":"gettingstarted/installrun/","text":"Installing and running PCOT PCOT is available in two forms: a standalone executable and a source distribution. While the standalone version is much easier to install, it's harder to use as a library and to modify. It's also quite a large file. Standalone version The standalone executables are available on request from the Aberystwyth team. Once you have the appropriate executable for your operating system, just run it to run PCOT. No installation is necessary. Installing from source PCOT is a Python program (and library) with a number of dependencies, including Python >3.8 PyQt OpenCV numpy scikit-image pyperclip (may also require other packages in Linux e.g. xsel) matplotlib Install Anaconda We find the best way to manage these is to use Anaconda. Installation has been tested on Windows 10, MacOS and Ubuntu 20.04. The first thing you will need to do is install Anaconda, which can be done from here: Windows: https://docs.anaconda.com/anaconda/install/linux/ Linux: https://docs.anaconda.com/anaconda/install/linux/ MacOS: https://docs.anaconda.com/anaconda/install/mac-os/ (untested) Obtain the software This can be done by either downloading the archive from Github and extracting it into a new directory, or cloning the repository. In both cases, the top level directory should be called PCOT (this isn't really mandatory but makes the instructions below simpler). The best way to download is this: Make sure you have a Github account and membership of the AU-ExoMars group. Open an Anaconda shell window (see below) If you have an SSH key set up for GitHub, type this command into the shell ( changing the repository address if it is different ): git clone git@github.com:AU-ExoMars/PCOT.git Otherwise type this: git clone https://github.com/AU-ExoMars/PCOT.git You should now have a PCOT directory which will contain this file (as README.md) and quite a few others. Opening Anaconda's shell on different OSs Windows: Open the Anaconda PowerShell Prompt application, which will have been installed when you installed Anaconda. Linux and MacOS : just open a Bash shell Installing on Ubuntu / MacOS Assuming you have successfully installed Anaconda and cloned or downloaded PCOT as above: Open a bash shell cd to the PCOT directory (which contains this file). Run the command conda create -n pcot python=3.8 poetry . This will create an environment called pcot which uses Python 3.8 and the Poetry dependency and packaging manager. It may take some time. Activate the environment with conda activate pcot . Now run poetry install . This will set up all the packages PCOT is dependent on and install PCOT. You should now be able to run pcot to start the application. Installing on Windows Assuming you have successfully installed Anaconda and cloned or downloaded PCOT as above: Open the Anaconda PowerShell Prompt application from the Start Menu. cd to the PCOT directory (which contains this file). Run the command conda create -n pcot python=3.8 poetry . This will create an environment called pcot which uses Python 3.8 and the Poetry dependency and packaging manager. It may take some time. Activate the environment with conda activate pcot . Now run poetry install . This will set up all the packages PCOT is dependent on and install PCOT. You should now be able to run pcot to start the application. Running PCOT from source Open an Anaconda shell and run the following commands (assuming you installed PCOT into your home directory): conda activate pcot pcot If you have installed the binary version you don't need to activate a conda environment. Running PCOT inside Pycharm These instructions apply to source installations. First set up the Conda environment and interpreter: Open PyCharm and open the PCOT directory as an existing project. Open File/Settings.. (Ctrl+Alt+S) Select Project:PCOT / Python Interpreter If the Python Interpreter is not already Python 3.8 with something like anaconda3/envs/pcot/bin/python Select the cogwheel to the right of the Python Interpreter dropdown and then select Add . Select Conda Environment . Select Existing Environment . Select the environment: it should be something like anaconda3/envs/pcot/bin/python . Select OK . Now set up the run configuration: Select Edit Configurations... (or it might be Add Configuration... ) from the configurations drop down in the menu bar Add a new configuration (the + symbol) and select Python Set Script Path to PCOT/src/pcot/__main__.py Make sure the interpreter is something like Project Default (Python 3.8 (pcot)) , i.e. the Python interpreter of the pcot environment. You should now be able to run and debug PCOT. Environment variables It's a good idea, but not mandatory, to set the environment variable PCOTUSER to a string of the form name <email> . For example, in Linux I have added the following to my .bashrc file: export PCOT_USER=\"Jim Finnis <jcf12@aber.ac.uk>\" This data is added to all saved PCOT graphs. If the environment variable is not set, the username returned by Python's getpass module is used (e.g. 'jcf12'). In case of problems There are a few things which can stop PCOT running - see issues .","title":"Installing and running"},{"location":"gettingstarted/installrun/#installing-and-running-pcot","text":"PCOT is available in two forms: a standalone executable and a source distribution. While the standalone version is much easier to install, it's harder to use as a library and to modify. It's also quite a large file.","title":"Installing and running PCOT"},{"location":"gettingstarted/installrun/#standalone-version","text":"The standalone executables are available on request from the Aberystwyth team. Once you have the appropriate executable for your operating system, just run it to run PCOT. No installation is necessary.","title":"Standalone version"},{"location":"gettingstarted/installrun/#installing-from-source","text":"PCOT is a Python program (and library) with a number of dependencies, including Python >3.8 PyQt OpenCV numpy scikit-image pyperclip (may also require other packages in Linux e.g. xsel) matplotlib","title":"Installing from source"},{"location":"gettingstarted/installrun/#install-anaconda","text":"We find the best way to manage these is to use Anaconda. Installation has been tested on Windows 10, MacOS and Ubuntu 20.04. The first thing you will need to do is install Anaconda, which can be done from here: Windows: https://docs.anaconda.com/anaconda/install/linux/ Linux: https://docs.anaconda.com/anaconda/install/linux/ MacOS: https://docs.anaconda.com/anaconda/install/mac-os/ (untested)","title":"Install Anaconda"},{"location":"gettingstarted/installrun/#obtain-the-software","text":"This can be done by either downloading the archive from Github and extracting it into a new directory, or cloning the repository. In both cases, the top level directory should be called PCOT (this isn't really mandatory but makes the instructions below simpler). The best way to download is this: Make sure you have a Github account and membership of the AU-ExoMars group. Open an Anaconda shell window (see below) If you have an SSH key set up for GitHub, type this command into the shell ( changing the repository address if it is different ): git clone git@github.com:AU-ExoMars/PCOT.git Otherwise type this: git clone https://github.com/AU-ExoMars/PCOT.git You should now have a PCOT directory which will contain this file (as README.md) and quite a few others.","title":"Obtain the software"},{"location":"gettingstarted/installrun/#opening-anacondas-shell-on-different-oss","text":"Windows: Open the Anaconda PowerShell Prompt application, which will have been installed when you installed Anaconda. Linux and MacOS : just open a Bash shell","title":"Opening Anaconda's shell on different OSs"},{"location":"gettingstarted/installrun/#installing-on-ubuntu-macos","text":"Assuming you have successfully installed Anaconda and cloned or downloaded PCOT as above: Open a bash shell cd to the PCOT directory (which contains this file). Run the command conda create -n pcot python=3.8 poetry . This will create an environment called pcot which uses Python 3.8 and the Poetry dependency and packaging manager. It may take some time. Activate the environment with conda activate pcot . Now run poetry install . This will set up all the packages PCOT is dependent on and install PCOT. You should now be able to run pcot to start the application.","title":"Installing on Ubuntu / MacOS"},{"location":"gettingstarted/installrun/#installing-on-windows","text":"Assuming you have successfully installed Anaconda and cloned or downloaded PCOT as above: Open the Anaconda PowerShell Prompt application from the Start Menu. cd to the PCOT directory (which contains this file). Run the command conda create -n pcot python=3.8 poetry . This will create an environment called pcot which uses Python 3.8 and the Poetry dependency and packaging manager. It may take some time. Activate the environment with conda activate pcot . Now run poetry install . This will set up all the packages PCOT is dependent on and install PCOT. You should now be able to run pcot to start the application.","title":"Installing on Windows"},{"location":"gettingstarted/installrun/#running-pcot-from-source","text":"Open an Anaconda shell and run the following commands (assuming you installed PCOT into your home directory): conda activate pcot pcot If you have installed the binary version you don't need to activate a conda environment.","title":"Running PCOT from source"},{"location":"gettingstarted/installrun/#running-pcot-inside-pycharm","text":"These instructions apply to source installations. First set up the Conda environment and interpreter: Open PyCharm and open the PCOT directory as an existing project. Open File/Settings.. (Ctrl+Alt+S) Select Project:PCOT / Python Interpreter If the Python Interpreter is not already Python 3.8 with something like anaconda3/envs/pcot/bin/python Select the cogwheel to the right of the Python Interpreter dropdown and then select Add . Select Conda Environment . Select Existing Environment . Select the environment: it should be something like anaconda3/envs/pcot/bin/python . Select OK . Now set up the run configuration: Select Edit Configurations... (or it might be Add Configuration... ) from the configurations drop down in the menu bar Add a new configuration (the + symbol) and select Python Set Script Path to PCOT/src/pcot/__main__.py Make sure the interpreter is something like Project Default (Python 3.8 (pcot)) , i.e. the Python interpreter of the pcot environment. You should now be able to run and debug PCOT.","title":"Running PCOT inside Pycharm"},{"location":"gettingstarted/installrun/#environment-variables","text":"It's a good idea, but not mandatory, to set the environment variable PCOTUSER to a string of the form name <email> . For example, in Linux I have added the following to my .bashrc file: export PCOT_USER=\"Jim Finnis <jcf12@aber.ac.uk>\" This data is added to all saved PCOT graphs. If the environment variable is not set, the username returned by Python's getpass module is used (e.g. 'jcf12').","title":"Environment variables"},{"location":"gettingstarted/installrun/#in-case-of-problems","text":"There are a few things which can stop PCOT running - see issues .","title":"In case of problems"},{"location":"gettingstarted/issues/","text":"Common runtime issues Can't start Qt on Linux This sometimes happens: qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"\" even though it was found. This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem. Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, webgl, xcb. Try this: export QT_DEBUG_PLUGINS=1 pcot to run the program again, and look at the output. You might see errors like this (I've removed some stuff): QFactoryLoader::QFactoryLoader() checking directory path \"[...]envs/pcot/bin/platforms\" ... Cannot load library [...]/plugins/platforms/libqxcb.so: (libxcb-xinerama.so.0: cannot open shared object file: No such file or directory) QLibraryPrivate::loadPlugin failed on \"...[stuff removed].. (libxcb-xinerama.so.0: cannot open shared object file: No such file or directory)\" If that's the case, install the missing package: sudo apt install libxcb-xinerama0 That might help. Otherwise, send a message to us with the output from the QT_DEBUG_PLUGINS run and we will investigate.","title":"Known issues"},{"location":"gettingstarted/issues/#common-runtime-issues","text":"","title":"Common runtime issues"},{"location":"gettingstarted/issues/#cant-start-qt-on-linux","text":"This sometimes happens: qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"\" even though it was found. This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem. Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, webgl, xcb. Try this: export QT_DEBUG_PLUGINS=1 pcot to run the program again, and look at the output. You might see errors like this (I've removed some stuff): QFactoryLoader::QFactoryLoader() checking directory path \"[...]envs/pcot/bin/platforms\" ... Cannot load library [...]/plugins/platforms/libqxcb.so: (libxcb-xinerama.so.0: cannot open shared object file: No such file or directory) QLibraryPrivate::loadPlugin failed on \"...[stuff removed].. (libxcb-xinerama.so.0: cannot open shared object file: No such file or directory)\" If that's the case, install the missing package: sudo apt install libxcb-xinerama0 That might help. Otherwise, send a message to us with the output from the QT_DEBUG_PLUGINS run and we will investigate.","title":"Can't start Qt on Linux"},{"location":"gettingstarted/tutorial/","text":"Getting started with PCOT This page is a gentle introduction to PCOT's user interface elements, and will walk you through loading image data and performing some simple manipulations. There is a video guide - please ignore the opening comments on installation and Anaconda; these only apply to installing from source Be aware that this is very much an early version and there are no doubt a lot of serious problems! Introduction to the UI The image below shows the PCOT interface (with some extra information in red). Figure: The PCOT user interface. Click on image to expand. The window is divided into several areas: At the top, the input buttons each open one of PCOT's input windows. These describe how information is read into PCOT. Below this and to the left is the node tab area , which will be empty on startup. Double-clicking on a node in the graph (see below) will open a tab for that node, allowing you to view it and edit its parameters. To the right of the tab area is the graph . This shows the nodes in the document and their connections. To the right of the graph is the palette . Clicking on a button in the palette will add a node of the given type to the graph. At the bottom is the log area and a set of global controls . Working with graph nodes Selecting in the graph When you open the program, the first thing you will see is a graph containing a single input node, with no nodes open. You can select a node in the graph by clicking on it, or by dragging a box which intersects the node. A selected node will be tinted blue. Opening a node's tab for editing Double-clicking on a node will open that node's tab for editing. If you double-click on the input node, it will turn a dark cyan colour and the node's tab will appear on the left: Figure: An open but unused input node. Click on image to expand. The node is cyan because the currently selected tab's node is tinted green, and the node is already tinted blue because it is selected. There are two selection models: Multiple nodes can be selected in the graph; these are tinted blue. A single node's tab can be open and currently being edited, this node is tinted green in the graph. Nodes which are both being edited and are selected are tinted cyan. Creating a new node This can be done in two ways: Clicking on a node type in the palette will create a new instance of that type in the graph, hopefully somewhere sensible. Right-clicking a node type from the palette and dragging onto the graph will create a node where you wish. \"Undocking\" a node's tab Sometimes it is useful to see several node tabs at the same time. Double-clicking on the actual \"tab\" part, where the name of the node type appears, will make the tab open in a separate window. This can be done for several tabs, and the windows can be rearranged as you wish. Closing the window will \"redock\" the tab so it appears in the tab area as before. Constant and comment nodes These two nodes are special - the boxes in the graph have text fields which can be edited. For constant nodes, the value in the box will be the numeric output of the node. This node has no tab, and double-clicking has no effect. For comment nodes, the value in the box is a text comment that can help other users navigate the graph. Once edited, the box can be resized by clicking and dragging its bottom-right corner. The text will flow to fit the box. Double-clicking on a comment node opens a tab which provides an alternative way of editing the text, as well as changing the font size and colours. It's also the only way of getting blank lines into the text, since hitting the \"enter\" key will stop editing when you are editing the node text directly in its box. Figure: Comment and constant nodes. Click on image to expand. Canvases Most nodes use a canvas to display some bands of an image as RGB. This will take up a large proportion of their tab - in some cases (such as input ) all of it, with no other controls. It is worth discussing in some detail. The main area of the canvas is blue if no image is currently input. You can pan the canvas using the scroll bars at the edge, and zoom with the mouse wheel. The button at bottom right will reset to show the entire image. Above the canvas itself are three combo boxes which determine the image mapping : how the bands within the (probably) multispectral image map onto RGB channels for viewing. Each band in the combo box shows the input number, a colon, and typically the name, position or wavelength of the band. Exactly what is shown depends on the image being loaded and the Caption global control . It is also possible to save the RGB-mapped image as a PNG, and show any regions of interest which have been added to the image. Loading an image For now, we will load an RGB image into PCOT. Clicking on the Input 0 button at the top of the main window will open the first of the four input's editor window. This will show a number of buttons, one for each input method. Click on RGB, and the window will show that input's RGB method settings and select the RGB method as being active (see below). Using the directory tree widget, double-click any image file (PNG or RGB). The canvas on the right-hand side will show the image selected, and you can modify how the RGB channels are mapped using the three source widgets as described above. Here, the widgets will just hold \"R\", \"G\" and \"B\" as the source band names, because this is an RGB image source. Figure: An open RGB input. Click on image to expand. At the bottom right of the image are three source indicators : these show what bands within which inputs were used to generate the canvas image. They should show something like [0:R][0:G][0:B] meaning that the red channel was generated from the band labelled \"R\" in input 0, and so on. Manipulating an image Let's perform a simple manipulation on an RGB image. It's not what PCOT is for, but it will demonstrate some of the principles without requiring actual multispectral data. In this example, we'll generate a \"red/green slope\" image (which is pretty meaningless). Start PCOT and load an image into input 0 as before, by clicking on the Input 0 button, selecting RGB and double-clicking on an image file. Double-click on the input 0 node in the graph - instances of this node bring input 0 into the graph. Click on expr in the palette (on the right) to create an expression evaluation node. Drag a connection from the output of input 0 to the a input of expr Double-click on the expr node to open its tab for editing We now have an input feeding into an expression evaluator, which we can edit. First, let's just see one band. Click in the expr tab's expression box: this is the box which says \"Enter expression here...\". Enter the string a$R This says \"select band R from input a \" - \"R\" is the name given to the red channel in RGB images (in multispectral images we typically use wavelengths on the right-hand side of the $ operator, such as a$640 ). Press \"Run\" in the node's tab. You should now see a monochrome image in the node's canvas: the result of the calculation, containing only the red channel. Now change the expression to a$R - a$G and press \"Run\". This will set each pixel to the result of subtracting the green value for that pixel from the red value, giving us our \"red/green slope.\" You will probably see quite a mess, because the canvas expects data between 0 and 1 and some of the pixels will probably be negative. We need to normalise the image to that range. Change the expression to norm(a$R - a$G) and press \"Run\" again to see the final result. Note that the source indicators in the bottom left of the image are now displaying something like [0:G&0:R][0:G&0:R][0:G&0:R] This indicates that all three RGB channels shown in the canvas are getting their data from both the R and G bands of input 0. Getting help Nodes Inside the PCOT app there are three ways to get help on a node: Double-clicking on the little blue box in the top right corner of that node in the graph, Using the right-click context menu on a node, Using the right-click context menu on a button in the palette. The node help texts are also available in the automatically generated documentation . If this isn't enough, don't hesitate to contact the Aberystwyth team. Expressions Doing the above on an expr node will tell you what operations, functions and properties are available. This text is also available in the automatically generated documentation for this node . You can also get help on properties and functions by right clicking in the log box at the bottom and selecting the appropriate option. Inside the expression box in the expr node, you can right-click on most things and ask for help. Loading different image formats The examples above use RGB images, which aren't much use for real work. Other image formats are available: * ENVI images * \"multiband\" images (multiple monochrome PNG images, one per band) * PDS4 products (work in progress) Loading an ENVI image ENVI images consists of a header (.hdr) file and the actual data (.dat) file. Currently PCOT can only load ENVI files which are 32-bit floating point, BSQ (band sequential) interleaved. To load ENVI, open an input and click the ENVI button. A dialog will appear which is very similar to the RGB file dialog above , but showing ENVI header files instead of image files. Double-click on such a file to load its associated data, which is assumed to be in the same directory with the same name. Filter name and wavelength information will be taken from the file. Loading a \"multiband\" image Sometimes data is provided as a set of monochrome PNG files, although this is clearly far from ideal. In this case we need to tell PCOT how to work out which filter is being used for each file. Again, we open the dialog by clicking on an input button and clicking the appropriate method - \"Multifile\" in this case. This will open the ENVI dialog, which is rather more complex than the RGB or ENVI dialogs: Figure: An open ENVI input. Click on image to expand. The procedure here is roughly this: Make sure the file names contain the the lens (left or right) as L or R, and the filter position number. Work out a regular expression which can find these in the file name. Hopefully you can just use the default, which assumes that the filename contains a string like LWAC01 for left lens, position 01; or RWAC10 for right lens, position 10. If your filenames don't have this format and it's too difficult to rename them, you'll have to write an RE yourself or find a handy IT person to help. Get the files into a single directory and open the input dialog as shown above. Determine which camera configuration - PANCAM or AUPE - produced the images and set the Camera option accordingly. These two setups use different filter sets, and will translate filter positions into different filter wavelengths and names. Click the \"Get Directory\" button. In the new dialog, select a directory containing the ENVI .hdr files and their accompanying .dat files, and click \"Select Folder\". A lot of files will appear in the Files box. Double-click images to preview them as a single channel. If they are dark, select an appropriate multiplier and double-click again. Click in image checkboxes to select them; selected images will be combined into a single multispectral mage. Close the dialog when you have the selected images you want. It might be a good idea to create an input node to examine the resulting multispectral image. PDS4 products This is very much work in progress - please contact the developers if you need this functionality soon.","title":"Tutorial"},{"location":"gettingstarted/tutorial/#getting-started-with-pcot","text":"This page is a gentle introduction to PCOT's user interface elements, and will walk you through loading image data and performing some simple manipulations. There is a video guide - please ignore the opening comments on installation and Anaconda; these only apply to installing from source Be aware that this is very much an early version and there are no doubt a lot of serious problems!","title":"Getting started with PCOT"},{"location":"gettingstarted/tutorial/#introduction-to-the-ui","text":"The image below shows the PCOT interface (with some extra information in red). Figure: The PCOT user interface. Click on image to expand. The window is divided into several areas: At the top, the input buttons each open one of PCOT's input windows. These describe how information is read into PCOT. Below this and to the left is the node tab area , which will be empty on startup. Double-clicking on a node in the graph (see below) will open a tab for that node, allowing you to view it and edit its parameters. To the right of the tab area is the graph . This shows the nodes in the document and their connections. To the right of the graph is the palette . Clicking on a button in the palette will add a node of the given type to the graph. At the bottom is the log area and a set of global controls .","title":"Introduction to the UI"},{"location":"gettingstarted/tutorial/#working-with-graph-nodes","text":"","title":"Working with graph nodes"},{"location":"gettingstarted/tutorial/#selecting-in-the-graph","text":"When you open the program, the first thing you will see is a graph containing a single input node, with no nodes open. You can select a node in the graph by clicking on it, or by dragging a box which intersects the node. A selected node will be tinted blue.","title":"Selecting in the graph"},{"location":"gettingstarted/tutorial/#opening-a-nodes-tab-for-editing","text":"Double-clicking on a node will open that node's tab for editing. If you double-click on the input node, it will turn a dark cyan colour and the node's tab will appear on the left: Figure: An open but unused input node. Click on image to expand. The node is cyan because the currently selected tab's node is tinted green, and the node is already tinted blue because it is selected. There are two selection models: Multiple nodes can be selected in the graph; these are tinted blue. A single node's tab can be open and currently being edited, this node is tinted green in the graph. Nodes which are both being edited and are selected are tinted cyan.","title":"Opening a node's tab for editing"},{"location":"gettingstarted/tutorial/#creating-a-new-node","text":"This can be done in two ways: Clicking on a node type in the palette will create a new instance of that type in the graph, hopefully somewhere sensible. Right-clicking a node type from the palette and dragging onto the graph will create a node where you wish.","title":"Creating a new node"},{"location":"gettingstarted/tutorial/#undocking-a-nodes-tab","text":"Sometimes it is useful to see several node tabs at the same time. Double-clicking on the actual \"tab\" part, where the name of the node type appears, will make the tab open in a separate window. This can be done for several tabs, and the windows can be rearranged as you wish. Closing the window will \"redock\" the tab so it appears in the tab area as before.","title":"\"Undocking\" a node's tab"},{"location":"gettingstarted/tutorial/#constant-and-comment-nodes","text":"These two nodes are special - the boxes in the graph have text fields which can be edited. For constant nodes, the value in the box will be the numeric output of the node. This node has no tab, and double-clicking has no effect. For comment nodes, the value in the box is a text comment that can help other users navigate the graph. Once edited, the box can be resized by clicking and dragging its bottom-right corner. The text will flow to fit the box. Double-clicking on a comment node opens a tab which provides an alternative way of editing the text, as well as changing the font size and colours. It's also the only way of getting blank lines into the text, since hitting the \"enter\" key will stop editing when you are editing the node text directly in its box. Figure: Comment and constant nodes. Click on image to expand.","title":"Constant and comment nodes"},{"location":"gettingstarted/tutorial/#canvases","text":"Most nodes use a canvas to display some bands of an image as RGB. This will take up a large proportion of their tab - in some cases (such as input ) all of it, with no other controls. It is worth discussing in some detail. The main area of the canvas is blue if no image is currently input. You can pan the canvas using the scroll bars at the edge, and zoom with the mouse wheel. The button at bottom right will reset to show the entire image. Above the canvas itself are three combo boxes which determine the image mapping : how the bands within the (probably) multispectral image map onto RGB channels for viewing. Each band in the combo box shows the input number, a colon, and typically the name, position or wavelength of the band. Exactly what is shown depends on the image being loaded and the Caption global control . It is also possible to save the RGB-mapped image as a PNG, and show any regions of interest which have been added to the image.","title":"Canvases"},{"location":"gettingstarted/tutorial/#loading-an-image","text":"For now, we will load an RGB image into PCOT. Clicking on the Input 0 button at the top of the main window will open the first of the four input's editor window. This will show a number of buttons, one for each input method. Click on RGB, and the window will show that input's RGB method settings and select the RGB method as being active (see below). Using the directory tree widget, double-click any image file (PNG or RGB). The canvas on the right-hand side will show the image selected, and you can modify how the RGB channels are mapped using the three source widgets as described above. Here, the widgets will just hold \"R\", \"G\" and \"B\" as the source band names, because this is an RGB image source. Figure: An open RGB input. Click on image to expand. At the bottom right of the image are three source indicators : these show what bands within which inputs were used to generate the canvas image. They should show something like [0:R][0:G][0:B] meaning that the red channel was generated from the band labelled \"R\" in input 0, and so on.","title":"Loading an image"},{"location":"gettingstarted/tutorial/#manipulating-an-image","text":"Let's perform a simple manipulation on an RGB image. It's not what PCOT is for, but it will demonstrate some of the principles without requiring actual multispectral data. In this example, we'll generate a \"red/green slope\" image (which is pretty meaningless). Start PCOT and load an image into input 0 as before, by clicking on the Input 0 button, selecting RGB and double-clicking on an image file. Double-click on the input 0 node in the graph - instances of this node bring input 0 into the graph. Click on expr in the palette (on the right) to create an expression evaluation node. Drag a connection from the output of input 0 to the a input of expr Double-click on the expr node to open its tab for editing We now have an input feeding into an expression evaluator, which we can edit. First, let's just see one band. Click in the expr tab's expression box: this is the box which says \"Enter expression here...\". Enter the string a$R This says \"select band R from input a \" - \"R\" is the name given to the red channel in RGB images (in multispectral images we typically use wavelengths on the right-hand side of the $ operator, such as a$640 ). Press \"Run\" in the node's tab. You should now see a monochrome image in the node's canvas: the result of the calculation, containing only the red channel. Now change the expression to a$R - a$G and press \"Run\". This will set each pixel to the result of subtracting the green value for that pixel from the red value, giving us our \"red/green slope.\" You will probably see quite a mess, because the canvas expects data between 0 and 1 and some of the pixels will probably be negative. We need to normalise the image to that range. Change the expression to norm(a$R - a$G) and press \"Run\" again to see the final result. Note that the source indicators in the bottom left of the image are now displaying something like [0:G&0:R][0:G&0:R][0:G&0:R] This indicates that all three RGB channels shown in the canvas are getting their data from both the R and G bands of input 0.","title":"Manipulating an image"},{"location":"gettingstarted/tutorial/#getting-help","text":"","title":"Getting help"},{"location":"gettingstarted/tutorial/#nodes","text":"Inside the PCOT app there are three ways to get help on a node: Double-clicking on the little blue box in the top right corner of that node in the graph, Using the right-click context menu on a node, Using the right-click context menu on a button in the palette. The node help texts are also available in the automatically generated documentation . If this isn't enough, don't hesitate to contact the Aberystwyth team.","title":"Nodes"},{"location":"gettingstarted/tutorial/#expressions","text":"Doing the above on an expr node will tell you what operations, functions and properties are available. This text is also available in the automatically generated documentation for this node . You can also get help on properties and functions by right clicking in the log box at the bottom and selecting the appropriate option. Inside the expression box in the expr node, you can right-click on most things and ask for help.","title":"Expressions"},{"location":"gettingstarted/tutorial/#loading-different-image-formats","text":"The examples above use RGB images, which aren't much use for real work. Other image formats are available: * ENVI images * \"multiband\" images (multiple monochrome PNG images, one per band) * PDS4 products (work in progress)","title":"Loading different image formats"},{"location":"gettingstarted/tutorial/#loading-an-envi-image","text":"ENVI images consists of a header (.hdr) file and the actual data (.dat) file. Currently PCOT can only load ENVI files which are 32-bit floating point, BSQ (band sequential) interleaved. To load ENVI, open an input and click the ENVI button. A dialog will appear which is very similar to the RGB file dialog above , but showing ENVI header files instead of image files. Double-click on such a file to load its associated data, which is assumed to be in the same directory with the same name. Filter name and wavelength information will be taken from the file.","title":"Loading an ENVI image"},{"location":"gettingstarted/tutorial/#loading-a-multiband-image","text":"Sometimes data is provided as a set of monochrome PNG files, although this is clearly far from ideal. In this case we need to tell PCOT how to work out which filter is being used for each file. Again, we open the dialog by clicking on an input button and clicking the appropriate method - \"Multifile\" in this case. This will open the ENVI dialog, which is rather more complex than the RGB or ENVI dialogs: Figure: An open ENVI input. Click on image to expand. The procedure here is roughly this: Make sure the file names contain the the lens (left or right) as L or R, and the filter position number. Work out a regular expression which can find these in the file name. Hopefully you can just use the default, which assumes that the filename contains a string like LWAC01 for left lens, position 01; or RWAC10 for right lens, position 10. If your filenames don't have this format and it's too difficult to rename them, you'll have to write an RE yourself or find a handy IT person to help. Get the files into a single directory and open the input dialog as shown above. Determine which camera configuration - PANCAM or AUPE - produced the images and set the Camera option accordingly. These two setups use different filter sets, and will translate filter positions into different filter wavelengths and names. Click the \"Get Directory\" button. In the new dialog, select a directory containing the ENVI .hdr files and their accompanying .dat files, and click \"Select Folder\". A lot of files will appear in the Files box. Double-click images to preview them as a single channel. If they are dark, select an appropriate multiplier and double-click again. Click in image checkboxes to select them; selected images will be combined into a single multispectral mage. Close the dialog when you have the selected images you want. It might be a good idea to create an input node to examine the resulting multispectral image.","title":"Loading a \"multiband\" image"},{"location":"gettingstarted/tutorial/#pds4-products","text":"This is very much work in progress - please contact the developers if you need this functionality soon.","title":"PDS4 products"},{"location":"userguide/","text":"Overview These pages are a reference guide to PCOT. At the moment, this consists of in-depth pages on particular aspects of PCOT. For introductory information see the Getting Started section, which will tell you how to install and run PCOT and give you a tutorial covering the basics. Contents Operating principles Automatically generated documentation for nodes, expression functions and expression properties. Global controls on the PCOT UI. The canvas and its optional views","title":"Overview"},{"location":"userguide/#overview","text":"These pages are a reference guide to PCOT. At the moment, this consists of in-depth pages on particular aspects of PCOT. For introductory information see the Getting Started section, which will tell you how to install and run PCOT and give you a tutorial covering the basics.","title":"Overview"},{"location":"userguide/#contents","text":"Operating principles Automatically generated documentation for nodes, expression functions and expression properties. Global controls on the PCOT UI. The canvas and its optional views","title":"Contents"},{"location":"userguide/canvas/","text":"The Canvas and its optional views TODO User guide for the ubiquitous Canvas view These are TODO: Pixel information bits Uncertainty Filter aberration (if that's the right word) See Principles for details of how this should work","title":"The Canvas"},{"location":"userguide/canvas/#the-canvas-and-its-optional-views","text":"TODO User guide for the ubiquitous Canvas view These are TODO: Pixel information bits Uncertainty Filter aberration (if that's the right word) See Principles for details of how this should work","title":"The Canvas and its optional views"},{"location":"userguide/globalcontrols/","text":"Global controls These are at the bottom right of the PCOT main window, and currently consist of: Caption : select how different bands are labelled in the dropdown: Filter names - bands will be labelled by the name of the filter, e.g. \"C01L\" for the 640nm left-hand red broadband colour filter. Filter positions - the filter's position will be used, e.g. \"L07\" will be used for the C01L band, because it is the filter in position 7 on the left WAC. Wavelengths labels bands according to their centre wavelength, so the same band will be labelled \"640\" under this scheme. Autorun on change will cause each node to automatically perform its action when it is changed (either an input has changed or one of the controls in its tab). This will also cause all nodes \"downstream\" of it in the graph to change. It is sometimes useful to turn this off when changing a node will trigger a very slow action. Run all will cause all root nodes (nodes without inputs) in the graph to run, thus causing all their downstream nodes to run. Effectively, it runs all the nodes in the graph in the correct order.","title":"Global controls"},{"location":"userguide/globalcontrols/#global-controls","text":"These are at the bottom right of the PCOT main window, and currently consist of: Caption : select how different bands are labelled in the dropdown: Filter names - bands will be labelled by the name of the filter, e.g. \"C01L\" for the 640nm left-hand red broadband colour filter. Filter positions - the filter's position will be used, e.g. \"L07\" will be used for the C01L band, because it is the filter in position 7 on the left WAC. Wavelengths labels bands according to their centre wavelength, so the same band will be labelled \"640\" under this scheme. Autorun on change will cause each node to automatically perform its action when it is changed (either an input has changed or one of the controls in its tab). This will also cause all nodes \"downstream\" of it in the graph to change. It is sometimes useful to turn this off when changing a node will trigger a very slow action. Run all will cause all root nodes (nodes without inputs) in the graph to run, thus causing all their downstream nodes to run. Effectively, it runs all the nodes in the graph in the correct order.","title":"Global controls"},{"location":"userguide/principles/","text":"Operating principles PCOT nodes need to follow a set of rules to ensure that the information they process is handled consistently. This page describes these rules, most of which apply to image data. Source handling rules Each datum handled by PCOT has a \"source set\" describing where that datum ultimately comes from. Sources vary: in images, each band in an input image carries a source datum describing where it comes from. For a PDS4 source it could be a LIDVID, or it could simply be a filename (although ideally it should have some archive indexing data). Because data can be combined in various ways, each datum could have multiple sources. Image data in PCOT have a separate source set for each band. The rules for sources are simple: Every datum has a source set. This may be a null source if the datum is generated internally (consider the output from constant nodes). In the case of an image, this source set is actually a separate source set for each band, but may still be considered as a single source set for some operations (since the union of the band sets is available). If a datum, or band in a multi-band image, is constructed from data from more than once source set, the resulting datum or band consists of the union of the sets. As an example, consider the rather contrived example below. Figure: An example graph with each datum marked as a black circle. Image inputs are in yellow, scalar inputs are in blue.. Click on image to expand. We have three inputs into the graph: Input 0 has an image with three bands centered on 640nm, 540nm and 440nm. Input 1 has a different image with four bands. Input 2 has a numeric value of 0.2 (perhaps a housekeeping datum of some kind). These data are then combined in various ways: Input 1 is converted to a single greyscale band and multiplied by input 2 (the scalar 0.2) The result of this operation is then added to the 540nm band of input 0. What do the sources look like for each datum? Datum A is an image, and as such it has one source set per band. Each source set consists of a single \"image source\" giving details of input and filter wavelength. So here, the sources for A could be written as [ {0:640}, {0:540}, {0:440} ] That is, a list of three sets, each of which contains a single source which I've written in the form input:wavelength . Datum B is the extracted 540nm band of input A, so its sources are: [ {0:540} ] Datum C is another multiband image, this time from input 1: [ {1:780}, {1:640}, {1:540}, {1:440} ] Datum D is the greyscale conversion of Datum C above. This creates a single-band image, but that band combines all the bands of datum C. This results in a single source set containing all the bands: [ {1:780, 1:640, 1:540, 1:440} ] Datum E is the only non-image source. I will denote it here as just \"2\" indicating that it is input 2. It is worth noting here that sources may contain a lot of extra data describing exactly where they come from. For example, this input may come from PDS4, in which case at least the LIDVID will be included. But for now this is simply {2} Note that this is not shown as a list because it is not a multiband source. Datum F multiplies each band in datum D by the scalar E. This means that the source for E must be added to the source set for each band. There is only one band at this point because of the greyscale conversion: [ {1:780, 1:640, 1:540, 1:440, 2} ] Finally, we add the single-band images B and F together, resulting in another single-band image. This addition is done bandwise. There is only one band, so the result is: [ {1:780, 1:640, 1:540, 1:440, 2, 0:540} ] ROI rules TODO - ROI rules in progress. Images may contain regions of interest. If this is the case, then any operation should only be performed on the region of interest if possible. However, the rest of the image should be passed through unchanged to provide context - it is always possible to use a croproi node before the operation if cropping is required. This rule has the following practical outcomes, in which images are denoted by capitals A, B, \\dots A, B, \\dots scalars are denoted by lowercase x, y, \\dots x, y, \\dots the ROIs of image A A are the set R_A R_A So: In binary operations on an image and a scalar such as x+A x+A or A+x A+x , the operation is only performed on the region covered by the union of all ROIs on A A . Other parts of A A are left unchanged in the output, which carries the same ROIs. In binary operations on two images A+B A+B etc., at most one of the two images should have a region of interest (or union of multiple ROIs). If both images have an ROI the result is an error. The part of the resulting image outside the ROI comes from the input which does not have an ROI, as shown in the figure. Figure: Two images A and B, B has an ROI. In the result, the area covered by the ROI is A+B, the rest of the image is passed through from A (which has no ROI).. Click on image to expand. Originally the rule was that the intersection of the unions of the ROIs would be processed, while the rest of the output would be from the left-hand side (in the case of image data). That was too complicated, and broke the \"principle of least astonishment.\" If the user has put ROIs on both sides of their image they have probably made a mistake. Image quality data TODO - describe how these are processed. Could probably use a separate page describing the data? Consists of: image uncertainty map (float per band) image quality/info bits (byte per band) Uncertainty Each pixel each band of an imagecube usually contains an uncertainty value, which is a root mean squared error. Operations need to combine this data in a sensible way. For example, denoting the RMS error in a a as \\Delta a \\Delta a , binary operations work like this: \\begin{align} \\Delta (a+b), \\quad \\Delta (a+b) &= \\sqrt{(\\Delta a)^2 + (\\Delta b)^2}\\\\ \\Delta (ab),\\quad \\Delta (a/b) &= \\sqrt{\\left(\\frac{\\Delta a}{a}\\right)^2 + \\left(\\frac{\\Delta b}{b}\\right)^2}\\\\ \\Delta (a \\& b) &= \\min (\\Delta{a}, \\Delta{b})\\\\ \\Delta (a | b) &= \\max (\\Delta{a}, \\Delta{b}) \\end{align} \\begin{align} \\Delta (a+b), \\quad \\Delta (a+b) &= \\sqrt{(\\Delta a)^2 + (\\Delta b)^2}\\\\ \\Delta (ab),\\quad \\Delta (a/b) &= \\sqrt{\\left(\\frac{\\Delta a}{a}\\right)^2 + \\left(\\frac{\\Delta b}{b}\\right)^2}\\\\ \\Delta (a \\& b) &= \\min (\\Delta{a}, \\Delta{b})\\\\ \\Delta (a | b) &= \\max (\\Delta{a}, \\Delta{b}) \\end{align} Remember that this only applies if the bands are independent. In reality there is always a covariance between them. Not all images contain uncertainty data - it may be that the input image doesn't have this data, or that a function has been performed on the image which does not permit uncertainty data to be carried through (consider a decorrelation stretch, for example). In this case, this should be clearly visible in the canvas . Pixel information bits A lot of this is TODO Each pixel in each band has an associated set of bits which indicate error states, etc. Bits are: Bit name Meaning Effect on calculations ERROR Pixel is an error in this band should not be used in any calculation (see below). SATHIGH Pixel is saturated high in this band ??? SATLOW Pixel is saturated low in this band (i.e. zero or less) ??? When a pixel is not used in a particular band, the value is set to zero for that band and the ERROR bit is passed through. It should be possible to set bits based on per-pixel conditions with the bits node. For example, convert all uncertainties greater than a given value into errors. In fact, this should be done by default for a certain global value if possible. In general, when multiple image bands are combined (either from the same image or from different images) these are OR-ed together. This typically happens in a band-wise fashion because images are combined band-wise. Thus, when two images a a and b b are added, and the bits for channel i i of image a a are B_i(a) B_i(a) , \\[ B_i(a+b) = B_i(a) \\vee B_i(b)\\quad \\text{for all channels } i \\] However, some operations have a more complex flow of information. For example, a decorrelation stretch results in information from all bands being used in each band. In cases like this, the resulting bands are all ORed toether: \\[ B_i(\\text{decorr}(a)) = \\bigvee_i B_i(a) \\] Nodes which produce a scalar should ignore error pixels (e.g. finding the mean value) Nodes which perform a convolution operation or similar should propagate the error pixel to all affected pixels, leading to a blob of pixels in the output. I realise This isn't ideal ; another possibility could be to just zero the mask? But then we lose the error data. At the moment I don't believe we have any \"non-local\" behaviour where pixels affect regions of pixels in the output, so the point could be moot. Error ROIs It should be possible to construct an ROI of error or non-error pixels in an image (i.e. pixels which have an error on any band). Filter aberration A lot of this is TODO The filter wavelengths are only accurate for pixels in the centre of the image, due to the difference in the light path through the filter at different angles of incidence. Therefore: There will be a system in place to calculate the actual filter wavelength for a given pixel and use this in spectral plots (using the centre of the ROI for the spectrum node) A function should be available to generate the filter aberration value in expr - this would allow an \"image\" to be made of the aberration value which could be used in calculations It should be possible to set the ERROR bit for excessive aberration values Canvas information Again, TODO The following should be visible in the canvas as optional overlays: Pixel information bits as colour overlays (default ON) Uncertainty data (default OFF) Filter aberration as a heat map (default OFF)","title":"Operating principles"},{"location":"userguide/principles/#operating-principles","text":"PCOT nodes need to follow a set of rules to ensure that the information they process is handled consistently. This page describes these rules, most of which apply to image data.","title":"Operating principles"},{"location":"userguide/principles/#source-handling-rules","text":"Each datum handled by PCOT has a \"source set\" describing where that datum ultimately comes from. Sources vary: in images, each band in an input image carries a source datum describing where it comes from. For a PDS4 source it could be a LIDVID, or it could simply be a filename (although ideally it should have some archive indexing data). Because data can be combined in various ways, each datum could have multiple sources. Image data in PCOT have a separate source set for each band. The rules for sources are simple: Every datum has a source set. This may be a null source if the datum is generated internally (consider the output from constant nodes). In the case of an image, this source set is actually a separate source set for each band, but may still be considered as a single source set for some operations (since the union of the band sets is available). If a datum, or band in a multi-band image, is constructed from data from more than once source set, the resulting datum or band consists of the union of the sets. As an example, consider the rather contrived example below. Figure: An example graph with each datum marked as a black circle. Image inputs are in yellow, scalar inputs are in blue.. Click on image to expand. We have three inputs into the graph: Input 0 has an image with three bands centered on 640nm, 540nm and 440nm. Input 1 has a different image with four bands. Input 2 has a numeric value of 0.2 (perhaps a housekeeping datum of some kind). These data are then combined in various ways: Input 1 is converted to a single greyscale band and multiplied by input 2 (the scalar 0.2) The result of this operation is then added to the 540nm band of input 0. What do the sources look like for each datum? Datum A is an image, and as such it has one source set per band. Each source set consists of a single \"image source\" giving details of input and filter wavelength. So here, the sources for A could be written as [ {0:640}, {0:540}, {0:440} ] That is, a list of three sets, each of which contains a single source which I've written in the form input:wavelength . Datum B is the extracted 540nm band of input A, so its sources are: [ {0:540} ] Datum C is another multiband image, this time from input 1: [ {1:780}, {1:640}, {1:540}, {1:440} ] Datum D is the greyscale conversion of Datum C above. This creates a single-band image, but that band combines all the bands of datum C. This results in a single source set containing all the bands: [ {1:780, 1:640, 1:540, 1:440} ] Datum E is the only non-image source. I will denote it here as just \"2\" indicating that it is input 2. It is worth noting here that sources may contain a lot of extra data describing exactly where they come from. For example, this input may come from PDS4, in which case at least the LIDVID will be included. But for now this is simply {2} Note that this is not shown as a list because it is not a multiband source. Datum F multiplies each band in datum D by the scalar E. This means that the source for E must be added to the source set for each band. There is only one band at this point because of the greyscale conversion: [ {1:780, 1:640, 1:540, 1:440, 2} ] Finally, we add the single-band images B and F together, resulting in another single-band image. This addition is done bandwise. There is only one band, so the result is: [ {1:780, 1:640, 1:540, 1:440, 2, 0:540} ]","title":"Source handling rules"},{"location":"userguide/principles/#roi-rules","text":"TODO - ROI rules in progress. Images may contain regions of interest. If this is the case, then any operation should only be performed on the region of interest if possible. However, the rest of the image should be passed through unchanged to provide context - it is always possible to use a croproi node before the operation if cropping is required. This rule has the following practical outcomes, in which images are denoted by capitals A, B, \\dots A, B, \\dots scalars are denoted by lowercase x, y, \\dots x, y, \\dots the ROIs of image A A are the set R_A R_A So: In binary operations on an image and a scalar such as x+A x+A or A+x A+x , the operation is only performed on the region covered by the union of all ROIs on A A . Other parts of A A are left unchanged in the output, which carries the same ROIs. In binary operations on two images A+B A+B etc., at most one of the two images should have a region of interest (or union of multiple ROIs). If both images have an ROI the result is an error. The part of the resulting image outside the ROI comes from the input which does not have an ROI, as shown in the figure. Figure: Two images A and B, B has an ROI. In the result, the area covered by the ROI is A+B, the rest of the image is passed through from A (which has no ROI).. Click on image to expand. Originally the rule was that the intersection of the unions of the ROIs would be processed, while the rest of the output would be from the left-hand side (in the case of image data). That was too complicated, and broke the \"principle of least astonishment.\" If the user has put ROIs on both sides of their image they have probably made a mistake.","title":"ROI rules"},{"location":"userguide/principles/#image-quality-data","text":"TODO - describe how these are processed. Could probably use a separate page describing the data? Consists of: image uncertainty map (float per band) image quality/info bits (byte per band)","title":"Image quality data"},{"location":"userguide/principles/#uncertainty","text":"Each pixel each band of an imagecube usually contains an uncertainty value, which is a root mean squared error. Operations need to combine this data in a sensible way. For example, denoting the RMS error in a a as \\Delta a \\Delta a , binary operations work like this: \\begin{align} \\Delta (a+b), \\quad \\Delta (a+b) &= \\sqrt{(\\Delta a)^2 + (\\Delta b)^2}\\\\ \\Delta (ab),\\quad \\Delta (a/b) &= \\sqrt{\\left(\\frac{\\Delta a}{a}\\right)^2 + \\left(\\frac{\\Delta b}{b}\\right)^2}\\\\ \\Delta (a \\& b) &= \\min (\\Delta{a}, \\Delta{b})\\\\ \\Delta (a | b) &= \\max (\\Delta{a}, \\Delta{b}) \\end{align} \\begin{align} \\Delta (a+b), \\quad \\Delta (a+b) &= \\sqrt{(\\Delta a)^2 + (\\Delta b)^2}\\\\ \\Delta (ab),\\quad \\Delta (a/b) &= \\sqrt{\\left(\\frac{\\Delta a}{a}\\right)^2 + \\left(\\frac{\\Delta b}{b}\\right)^2}\\\\ \\Delta (a \\& b) &= \\min (\\Delta{a}, \\Delta{b})\\\\ \\Delta (a | b) &= \\max (\\Delta{a}, \\Delta{b}) \\end{align} Remember that this only applies if the bands are independent. In reality there is always a covariance between them. Not all images contain uncertainty data - it may be that the input image doesn't have this data, or that a function has been performed on the image which does not permit uncertainty data to be carried through (consider a decorrelation stretch, for example). In this case, this should be clearly visible in the canvas .","title":"Uncertainty"},{"location":"userguide/principles/#pixel-information-bits","text":"A lot of this is TODO Each pixel in each band has an associated set of bits which indicate error states, etc. Bits are: Bit name Meaning Effect on calculations ERROR Pixel is an error in this band should not be used in any calculation (see below). SATHIGH Pixel is saturated high in this band ??? SATLOW Pixel is saturated low in this band (i.e. zero or less) ??? When a pixel is not used in a particular band, the value is set to zero for that band and the ERROR bit is passed through. It should be possible to set bits based on per-pixel conditions with the bits node. For example, convert all uncertainties greater than a given value into errors. In fact, this should be done by default for a certain global value if possible. In general, when multiple image bands are combined (either from the same image or from different images) these are OR-ed together. This typically happens in a band-wise fashion because images are combined band-wise. Thus, when two images a a and b b are added, and the bits for channel i i of image a a are B_i(a) B_i(a) , \\[ B_i(a+b) = B_i(a) \\vee B_i(b)\\quad \\text{for all channels } i \\] However, some operations have a more complex flow of information. For example, a decorrelation stretch results in information from all bands being used in each band. In cases like this, the resulting bands are all ORed toether: \\[ B_i(\\text{decorr}(a)) = \\bigvee_i B_i(a) \\] Nodes which produce a scalar should ignore error pixels (e.g. finding the mean value) Nodes which perform a convolution operation or similar should propagate the error pixel to all affected pixels, leading to a blob of pixels in the output. I realise This isn't ideal ; another possibility could be to just zero the mask? But then we lose the error data. At the moment I don't believe we have any \"non-local\" behaviour where pixels affect regions of pixels in the output, so the point could be moot.","title":"Pixel information bits"},{"location":"userguide/principles/#error-rois","text":"It should be possible to construct an ROI of error or non-error pixels in an image (i.e. pixels which have an error on any band).","title":"Error ROIs"},{"location":"userguide/principles/#filter-aberration","text":"A lot of this is TODO The filter wavelengths are only accurate for pixels in the centre of the image, due to the difference in the light path through the filter at different angles of incidence. Therefore: There will be a system in place to calculate the actual filter wavelength for a given pixel and use this in spectral plots (using the centre of the ROI for the spectrum node) A function should be available to generate the filter aberration value in expr - this would allow an \"image\" to be made of the aberration value which could be used in calculations It should be possible to set the ERROR bit for excessive aberration values","title":"Filter aberration"},{"location":"userguide/principles/#canvas-information","text":"Again, TODO The following should be visible in the canvas as optional overlays: Pixel information bits as colour overlays (default ON) Uncertainty data (default OFF) Filter aberration as a heat map (default OFF)","title":"Canvas information"}]}