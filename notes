A graph is a digraph of transformations, each of which can have multiple inputs and outputs
and is polymorphic.

The inputs and outputs can be of a number of different types, and these form a hierarchy:
for example, an image filter might produce RGB888 images and some other transformation might
accept any kind of image.

The nodes in the graph are transformations, not data. The glyph for a transformation should
contain its name and type data.

Because of how Python does class attributes, I'm going to differentiate between transformations
and their type with singletons. Each type of transformation has a singleton object and a
factory for generating that transformation. The polymorphism takes place in the transformation
types, the transformations are of a single type with a reference to the singleton (this is 
also how I did it with Stumpy, and how Angort types work).

transformation type object attributes:
    name
    input connection names and types (tuple of (name,type))
    output connection names and types
    others
    
transformation attributes:
    input connections (i.e. references to outputs of transformations)
    output connections (i.e. references to inputs of transformations) (yes, we do it both ways)
            (connections are a tuple of (object,index) )
    products generated by the transformation, one for each output, of the appropriate type
    private data    

Type management is hairy, but really we only care if a datum is an image or not. So if we just
have an "is image" test, then we're fine. So let's say types are just names, and start "img" if they
are images. But try to keep this tight so we can refine it later if we need to.

What about drawing? To draw things, the graph has to be converted into a Qt scene graph.
Probably the most straightforward way to do this is to have a function just do it statically when
required, rather than somehow keeping two graph structures in sync.

Macros:

Macros are stored as a graph inside the .json file, where each macro
acts as a "prototype" - the main graph is stored under GRAPH, macros
are stored in a MACROS entry containing a dict of name->graph.

When a macro is instantiated, a new graph is created from the nodes
in the prototype (the entire graph is copied). A link to each macro
instance is added to the original macro prototype.
The reason is that each macro instance needs its own set of nodes
to ensure that multiple instances of a macro in a graph don't interfere
with each other.

When the macro instance graph runs, its IN components read their inputs
and copy them to their outputs. The graph is run. The OUT components read
their inputs and copy them to their outputs, which constitute the outputs
of the macro. There is some internal wiring handling the links between
the macro node's inputs and outputs and the internal IN/OUT components.

When a user opens a macro, they are viewing the prototype. Any change to
the prototype graph should be copied to all instance graphs.


A "sink" node in a macro will be displayed in the macro's canvas.

Macros can be duplicated from the macro editor, creating another macro
prototype.

When a node is edited the current "perform()" should be "changed()."
In a "normal" graph, this will cause the current perform action. In
a macro, it will cause the prototype to look up the corresponding
node in all the instances, and will run perform on them. This should
feed the outputs. It may then have to run perform() on the macro node,
to ensure the nodes downstream of the instance also run.

Need to find a way to avoid recursive macros, and to prevent
copy/paste of in/out nodes into "normal" graphs.


So:
    perform() in Tab and subclasses -> changed()
    perform() in XFormGraph -> changed()
    
    
Saving and loading:
    Macros can be saved in a library
    Macros can be imported from another file
    So I suppose a macro library is just another file with no main graph?

New imagecubes:
   Change pancamimages images to hold filter descriptors in an array
    and not a set; order is important.


Canvas:
    should display the channels in the cube selected for RGB
    should automatically select correct channels on initialisation
    RGB channels should be persistent
    
    How this works:
        Comboboxes at the top of the canvas, (red,green,blue)chan.
        In Canvas.display(img) these are set to the names of the channels
        in the image by calling addChannelsToChannelCombo.

NOT DONE YET:        

        display() is the key method: provided the channels are right
        when this is called, we're fine.
        
        Need to view image according to channel selection (I think
        this is done, via calling img.rgb() with the channel assignments)
        
        Need to be able to change channel assignments - connect up
        the comboboxes to note change, and save changed into chan
        assignments and call display() when they change. Could be
        nasty.
        Also read initial chan assignments into comboboxes
        (that's done in display() already).
        
        MASSIVE problem:
        * Many nodes assume RGB. They can't.
        * These nodes have to be able to get an rgb image
        * They have to use the channel assignments stored in the node?
        * That might not exist - probably need a way to do this, creating
          a default.
        * replace chanAssignments with a getter that will create one?
        * In some cases the image might not exist yet
        
        Channel assignments are now stored in the node.
        
        We need to save/load the triple.
